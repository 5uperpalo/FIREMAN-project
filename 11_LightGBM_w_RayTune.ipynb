{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports\n",
    "This notebook uses preprocessed dataset by following [notebook](12_PowerConverter_dataset_preprocessing.ipynb).\n",
    "\n",
    "**notes**\n",
    "* CPU monitoring in terminal:  \n",
    "```bash\n",
    "top\n",
    "```\n",
    "* GPU monitoring in terminal:  \n",
    "```bash\n",
    "pip install gpustat\n",
    "watch -c gpustat -cp --color\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "# to save results to data directory\n",
    "module_path = \"..\"\n",
    "if module_path not in sys.path:\n",
    "    sys.path.insert(1, module_path)\n",
    "# increase displayed columns in jupyter notebook\n",
    "pd.set_option(\"display.max_columns\", 200)\n",
    "pd.set_option(\"display.max_rows\", 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "dlopen(/Users/abeattie/miniconda/envs/FIREMAN-project/lib/python3.7/site-packages/lightgbm/lib_lightgbm.so, 0x0006): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\n  Referenced from: /Users/abeattie/miniconda/envs/FIREMAN-project/lib/python3.7/site-packages/lightgbm/lib_lightgbm.so\n  Reason: tried: '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/lib/libomp.dylib' (no such file), '/usr/lib/libomp.dylib' (no such file)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mOSError\u001B[0m                                   Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/rt/82pssgq96l9d_s3skbv32z5m0000gn/T/ipykernel_74043/3584744859.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      7\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      8\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mdill\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 9\u001B[0;31m \u001B[0;32mimport\u001B[0m \u001B[0mlightgbm\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mlgbm\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     10\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mlime\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     11\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mmatplotlib\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpyplot\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mplt\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda/envs/FIREMAN-project/lib/python3.7/site-packages/lightgbm/__init__.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mpathlib\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mPath\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      7\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 8\u001B[0;31m \u001B[0;32mfrom\u001B[0m \u001B[0;34m.\u001B[0m\u001B[0mbasic\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mBooster\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mDataset\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mSequence\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mregister_logger\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      9\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0;34m.\u001B[0m\u001B[0mcallback\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mearly_stopping\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlog_evaluation\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mprint_evaluation\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrecord_evaluation\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mreset_parameter\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     10\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0;34m.\u001B[0m\u001B[0mengine\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mCVBooster\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcv\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtrain\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda/envs/FIREMAN-project/lib/python3.7/site-packages/lightgbm/basic.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m    108\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    109\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 110\u001B[0;31m \u001B[0m_LIB\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_load_lib\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    111\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    112\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda/envs/FIREMAN-project/lib/python3.7/site-packages/lightgbm/basic.py\u001B[0m in \u001B[0;36m_load_lib\u001B[0;34m()\u001B[0m\n\u001B[1;32m     99\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlib_path\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    100\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 101\u001B[0;31m     \u001B[0mlib\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mctypes\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcdll\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mLoadLibrary\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlib_path\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    102\u001B[0m     \u001B[0mlib\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mLGBM_GetLastError\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrestype\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mctypes\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mc_char_p\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    103\u001B[0m     \u001B[0mcallback\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mctypes\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mCFUNCTYPE\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mctypes\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mc_char_p\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda/envs/FIREMAN-project/lib/python3.7/ctypes/__init__.py\u001B[0m in \u001B[0;36mLoadLibrary\u001B[0;34m(self, name)\u001B[0m\n\u001B[1;32m    440\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    441\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mLoadLibrary\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 442\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_dlltype\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    443\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    444\u001B[0m \u001B[0mcdll\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mLibraryLoader\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mCDLL\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda/envs/FIREMAN-project/lib/python3.7/ctypes/__init__.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, name, mode, handle, use_errno, use_last_error)\u001B[0m\n\u001B[1;32m    362\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    363\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mhandle\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 364\u001B[0;31m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_handle\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_dlopen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_name\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmode\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    365\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    366\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_handle\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mhandle\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mOSError\u001B[0m: dlopen(/Users/abeattie/miniconda/envs/FIREMAN-project/lib/python3.7/site-packages/lightgbm/lib_lightgbm.so, 0x0006): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\n  Referenced from: /Users/abeattie/miniconda/envs/FIREMAN-project/lib/python3.7/site-packages/lightgbm/lib_lightgbm.so\n  Reason: tried: '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/lib/libomp.dylib' (no such file), '/usr/lib/libomp.dylib' (no such file)"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import tracemalloc\n",
    "from copy import copy\n",
    "from datetime import datetime\n",
    "from time import time\n",
    "from typing import Union\n",
    "\n",
    "import dill\n",
    "import lightgbm as lgbm\n",
    "import lime\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from eli5 import explain_prediction_df, explain_weights, explain_weights_df\n",
    "from eli5.sklearn import PermutationImportance\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from lime.lime_tabular import LimeTabularExplainer\n",
    "from pytorch_widedeep import Tab2Vec\n",
    "from pytorch_widedeep.utils import LabelEncoder\n",
    "from sklearn.metrics import classification_report, log_loss, mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "import src\n",
    "from src import common\n",
    "\n",
    "tracemalloc.start()\n",
    "\n",
    "import tracemalloc\n",
    "\n",
    "import ray\n",
    "from ray import tune\n",
    "from ray.tune import JupyterNotebookReporter\n",
    "from ray.tune.integration.lightgbm import TuneReportCheckpointCallback\n",
    "from ray.tune.integration.wandb import WandbLogger\n",
    "from ray.tune.logger import DEFAULT_LOGGERS\n",
    "from ray.tune.schedulers import AsyncHyperBandScheduler\n",
    "\n",
    "tracemalloc.start()\n",
    "\n",
    "# temporarily remove deprecation warnings\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**identifiers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "column_types = common.json_load(\"#datasets/Colab_PowerConverter/column_types.json\")\n",
    "target = column_types[\"target\"]\n",
    "measurement_label = column_types[\"measurement_label\"]\n",
    "RANDOM_STATE = 1\n",
    "TEST_SIZE_TRAIN = 0.2\n",
    "TEST_SIZE_VALID = 0.5\n",
    "EMBEDDING = False\n",
    "TASK = \"multiclass\" #(or \"binary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"#datasets/Colab_PowerConverter/dataset.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this measurement did not have a fault (?)\n",
    "df = df[df[measurement_label]!=\"Single-Phase_Sensor_Fault\"]\n",
    "df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fault_dict = {}\n",
    "for label,i in zip(df[measurement_label].unique(), range(len(df[measurement_label].unique()))):\n",
    "    df.loc[(df[measurement_label]==label) & (df[target]==1), target] = int(i+1)\n",
    "    fault_dict[label] = int(i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imbalance of the classes\n",
    "df[target].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fault_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=[measurement_label], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_valid = train_test_split(df, test_size=TEST_SIZE_TRAIN, stratify=df[target], random_state=RANDOM_STATE)\n",
    "df_valid, df_test = train_test_split(df_valid, test_size=TEST_SIZE_VALID, stratify=df_valid[target], random_state=RANDOM_STATE)\n",
    "\n",
    "df_train.reset_index(inplace=True, drop=True)\n",
    "df_valid.reset_index(inplace=True, drop=True)\n",
    "df_test.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_scaled, Scaler = common.scale(df_train, [target], scaler_sk='Standard')\n",
    "df_valid_scaled, Scaler = common.scale(df_valid, [target], scaler_sk=Scaler)\n",
    "df_test_scaled, Scaler = common.scale(df_test, [target], scaler_sk=Scaler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical features tranformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if EMBEDDING:\n",
    "    CAT_FEATURE_TRANSFORMATION = \"Entity Embedding\"\n",
    "    if CAT_FEATURE_TRANSFORMATION == \"Label Encoding\":\n",
    "        label_encoder = LabelEncoder(cat_cols)\n",
    "        label_encoder.fit(data[cat_cols])\n",
    "\n",
    "        df_train_scaled_enc = df_train_scaled.copy()\n",
    "        df_valid_scaled_enc = df_valid_scaled.copy()\n",
    "        df_test_scaled_enc = df_test_scaled.copy()\n",
    "\n",
    "        df_train_scaled_enc[cat_cols] = label_encoder.transform(\n",
    "            df_train_scaled_enc[cat_cols]\n",
    "        )\n",
    "        df_valid_scaled_enc[cat_cols] = label_encoder.transform(\n",
    "            df_valid_scaled_enc[cat_cols]\n",
    "        )\n",
    "        df_test_scaled_enc[cat_cols] = label_encoder.transform(\n",
    "            df_test_scaled_enc[cat_cols]\n",
    "        )\n",
    "        df_test_scaled_enc[cat_cols].head()\n",
    "\n",
    "    if CAT_FEATURE_TRANSFORMATION == \"Entity Embedding\":\n",
    "        # using pretrained embedding from pytorch-widedeep model and its tab_preprocessor\n",
    "        with open(\"dl_entity_emb_model_\" + TASK + \".dill\", \"rb\") as f:\n",
    "            model = dill.load(f)\n",
    "        with open(\"dl_entity_emb_model_tab_preprocessor_\" + TASK + \".dill\", \"rb\") as f:\n",
    "            tab_preprocessor = dill.load(f)\n",
    "\n",
    "        t2v = Tab2Vec(model=model, tab_preprocessor=tab_preprocessor, return_dataframe=True)\n",
    "        df_train_scaled_enc, df_train_y = t2v.transform(\n",
    "            df_train_scaled, target_col=target_col\n",
    "        )\n",
    "        df_valid_scaled_enc, df_valid_y = t2v.transform(\n",
    "            df_valid_scaled, target_col=target_col\n",
    "        )\n",
    "        df_test_scaled_enc, df_test_y = t2v.transform(\n",
    "            df_test_scaled, target_col=target_col\n",
    "        )\n",
    "        df_train_scaled_enc[target_col] = df_train_y\n",
    "        df_valid_scaled_enc[target_col] = df_valid_y\n",
    "        df_test_scaled_enc[target_col] = df_test_y\n",
    "\n",
    "        cols_list = list(df_test_scaled_enc.columns)\n",
    "        cat_cols_emb = []\n",
    "        for cat_col in cat_cols:\n",
    "            r = re.compile(cat_col + \"*\")\n",
    "            cat_cols_emb.extend(list(filter(r.match, cols_list)))\n",
    "    # df_test_scaled_enc[cat_cols_emb].head()\n",
    "else:\n",
    "    df_train_scaled_enc = df_train_scaled.copy()\n",
    "    df_valid_scaled_enc = df_valid_scaled.copy()\n",
    "    df_test_scaled_enc = df_test_scaled.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train_scaled_enc = df_train_scaled_enc.sample(100000)\n",
    "# df_valid_scaled_enc = df_valid_scaled_enc.sample(30000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = df[target].nunique()\n",
    "NUM_CLASSES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Dataset, metric and objective functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {}\n",
    "if TASK == \"binary\" or TASK == \"multiclass\":\n",
    "    config[\"objective\"] = TASK\n",
    "    config[\"num_classes\"] = NUM_CLASSES\n",
    "\n",
    "if TASK == \"multiclass\":\n",
    "    ray_metric = \"multi_logloss\"\n",
    "\n",
    "if EMBEDDING:\n",
    "    if CAT_FEATURE_TRANSFORMATION == \"Label Encoding\":\n",
    "        lgb_cat_cols = cat_cols_f\n",
    "    if CAT_FEATURE_TRANSFORMATION == \"Entity Embedding\":\n",
    "        lgb_cat_cols = []\n",
    "else:\n",
    "    lgb_cat_cols = []\n",
    "\n",
    "lgbtrain = lgbm.Dataset(\n",
    "    df_train_scaled_enc.drop(columns=[target]),\n",
    "    df_train_scaled_enc[target],\n",
    "    categorical_feature=lgb_cat_cols,\n",
    "    free_raw_data=False,\n",
    ")\n",
    "lgbvalid = lgbm.Dataset(\n",
    "    df_valid_scaled_enc.drop(columns=[target]),\n",
    "    df_valid_scaled_enc[target],\n",
    "    reference=lgbtrain,\n",
    "    free_raw_data=False,\n",
    ")\n",
    "# Final TRAIN/TEST\n",
    "ftrain = pd.concat([df_train_scaled_enc, df_valid_scaled_enc]).reset_index(\n",
    "    drop=True\n",
    ")\n",
    "flgbtrain = lgbm.Dataset(\n",
    "    ftrain.drop(columns=[target]),\n",
    "    ftrain[target],\n",
    "    categorical_feature=lgb_cat_cols,\n",
    "    free_raw_data=False,\n",
    ")\n",
    "lgbtest = lgbm.Dataset(\n",
    "    df_test_scaled_enc.drop(columns=[target]),\n",
    "    df_test_scaled_enc[target],\n",
    "    categorical_feature=lgb_cat_cols,\n",
    "    reference=flgbtrain,\n",
    "    free_raw_data=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model = lgbm.train(\n",
    "    config,\n",
    "    flgbtrain,\n",
    "    valid_sets=[lgbvalid],\n",
    "    valid_names=[\"\"],\n",
    "    #feval=feval,\n",
    "    #fobj=fobj,\n",
    "    #callbacks=[log_evaluation()],\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TASK == \"binary\":\n",
    "    res = np.rint(model.predict(lgbtest.data))\n",
    "\n",
    "if TASK == \"multiclass\":\n",
    "    res = model.predict(lgbtest.data).argmax(1)\n",
    "\n",
    "result = pd.DataFrame({\"predicted\": res,\n",
    "                       \"ground_truth\": df_test[target].values,})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Classification report:\\n{}'.format(classification_report(result['predicted'], result['ground_truth'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## w RayTune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time()\n",
    "\n",
    "#config[\"eta\"] = tune.loguniform(1e-4, 1e-1),\n",
    "#config[\"subsample\"] = tune.uniform(0.5, 1.0),\n",
    "config[\"max_depth\"] = tune.randint(1, 9),\n",
    "# config[\"wandb\"][\"project\"] = \"GBM_classifier\",\n",
    "# config[\"wandb\"][\"api_key_file\"] = \"../data/wandb_api.key\",\n",
    "# config[\"wandb\"][\"log_config\"] = True\n",
    "\n",
    "\n",
    "def training_function(config, train, valid):\n",
    "    lgbm_config = config.copy()\n",
    "    #lgbm_config.pop(\"wandb\")\n",
    "    trainer = lgbm.train(\n",
    "        lgbm_config,\n",
    "        train,\n",
    "        valid_sets=[valid],\n",
    "        valid_names=[\"\"],\n",
    "        callbacks=[\n",
    "            TuneReportCheckpointCallback(\n",
    "                {\n",
    "                    ray_metric: ray_metric,\n",
    "                }\n",
    "            )\n",
    "        ],\n",
    "    )\n",
    "\n",
    "\n",
    "asha_scheduler = AsyncHyperBandScheduler(\n",
    "    time_attr=\"training_iteration\",\n",
    "    metric=ray_metric,\n",
    "    mode=\"min\",\n",
    "    max_t=100,\n",
    "    grace_period=10,\n",
    "    reduction_factor=3,\n",
    "    brackets=1,\n",
    ")\n",
    "\n",
    "analysis = tune.run(\n",
    "    tune.with_parameters(training_function, train=lgbtrain, valid=lgbvalid),\n",
    "    # resources_per_trial={\"cpu\": 4, \"gpu\": 0},\n",
    "    num_samples=2,\n",
    "    progress_reporter=JupyterNotebookReporter(overwrite=True),\n",
    "    scheduler=asha_scheduler,\n",
    "    config=config,\n",
    "    #loggers=DEFAULT_LOGGERS + (WandbLogger,),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.trial_dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train best params model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runtime = time() - start\n",
    "print(\"Optimization time:\\n{}\".format(runtime))\n",
    "\n",
    "params = copy(analysis.get_best_config(ray_metric, \"min\"))\n",
    "params.pop(\"wandb\")\n",
    "# params[\"n_estimators\"] = 1000\n",
    "\n",
    "start = time()\n",
    "model = lgbm.train(\n",
    "    params,\n",
    "    flgbtrain,\n",
    "    valid_sets=[lgbtest],\n",
    "    callbacks=[lgbm.log_evaluation(show_stdv=False)],\n",
    ")\n",
    "runtime = time() - start\n",
    "print(\"Final model training time:\\n{}\".format(str(datetime.timedelta(seconds=runtime))))a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorboard visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboard import notebook\n",
    "\n",
    "notebook.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir ~/ray_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}