{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stream-based machine learning pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%conda install -c conda-forge scikit-multiflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#https://scikit-multiflow.github.io/scikit-multiflow/documentation.html#learning-methods\n",
    "from skmultiflow.drift_detection import DDM\n",
    "from skmultiflow.drift_detection.eddm import EDDM\n",
    "from skmultiflow.drift_detection import PageHinkley\n",
    "from skmultiflow.drift_detection.adwin import ADWIN\n",
    "\n",
    "from skmultiflow.meta import AdaptiveRandomForest\n",
    "from skmultiflow.evaluation import EvaluatePrequential\n",
    "\n",
    "from skmultiflow.data import DataStream\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('workshop_dataset.csv',index_col=False)\n",
    "dataset_test = pd.read_csv('workshop_dataset_stream_testing.csv',index_col=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Concept Drift Detection\n",
    "I stole this picture from :\n",
    "\n",
    "    \"Gama, J., Žliobaitė, I., Bifet, A., Pechenizkiy, M., & Bouchachia, A. (2014). A survey on concept drift adaptation. ACM computing surveys (CSUR), 46(4), 1-37.\"\n",
    "    \n",
    "I think it nicely shows categoies of concept drifts.\n",
    "![missing_image](Pattern_of_change_over_time_(outlier_is_not_concept_drift).png \"Pattern of change over time (outlier is not concept drift)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check where the fault_id changes - i.e. the concept_drift should occur and mark that sample with \"1\" (initial sample has NA - fill with 0)\n",
    "dataset['fault_id_change'] = dataset['fault_id'].diff().fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# magnitude of row vectors - concept drift detectors take as input single value not list/vector\n",
    "dataset['magnitude'] = dataset[dataset.columns[:-1]].apply(np.linalg.norm, axis=1)\n",
    "data_stream = dataset['magnitude'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Change detected in data: 7644.600911861115 - at index: 28\n",
      "Change detected in data: 7619.368761792521 - at index: 57\n"
     ]
    }
   ],
   "source": [
    "adwin = ADWIN()\n",
    "ddm = DDM()\n",
    "eddm = EDDM()\n",
    "ph = PageHinkley()\n",
    "\n",
    "# Adding stream elements to ADWIN and verifying if drift occurred\n",
    "for i in range(len(data_stream))[:100]:\n",
    "    #adwin.add_element(data_stream[i])\n",
    "    #ddm.add_element(data_stream[i])\n",
    "    #eddm.add_element(data_stream[i])\n",
    "    ph.add_element(data_stream[i])\n",
    "    if ph.detected_change():\n",
    "        print('Change detected in data: ' + str(data_stream[i]) + ' - at index: ' + str(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Classification pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Prequential evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prequential Evaluation\n",
      "Evaluating 1 target(s).\n",
      "Pre-training on 200 sample(s).\n",
      "Evaluating...\n",
      " ###----------------- [15%] [54.88s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\skmultiflow\\metrics\\measure_collection.py:138: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return sum_value / self.sample_count\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " #################### [100%] [413.05s]\n",
      "Processed samples: 31700\n",
      "Mean performance:\n",
      "ARF - Accuracy     : 0.9896\n",
      "ARF - Kappa        : 0.9891\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[AdaptiveRandomForest(binary_split=False, disable_weighted_vote=False,\n",
       "                      drift_detection_method=ADWIN(delta=0.001), grace_period=50,\n",
       "                      lambda_value=6, leaf_prediction='nba',\n",
       "                      max_byte_size=33554432, max_features=7,\n",
       "                      memory_estimate_period=2000000, n_estimators=10,\n",
       "                      nb_threshold=0, no_preprune=False, nominal_attributes=None,\n",
       "                      performance_metric='acc', random_state=None,\n",
       "                      remove_poor_atts=False, split_confidence=0.01,\n",
       "                      split_criterion='info_gain', stop_mem_management=False,\n",
       "                      tie_threshold=0.05,\n",
       "                      warning_detection_method=ADWIN(delta=0.01))]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples = dataset.drop(columns=['fault_id', 'fault_id_change', 'magnitude'])\n",
    "labels  = dataset['fault_id'].to_frame()\n",
    "\n",
    "stream = DataStream(data = samples, y = labels)\n",
    "stream.prepare_for_use()\n",
    "\n",
    "ARF = AdaptiveRandomForest()\n",
    "\n",
    "evaluator = EvaluatePrequential(n_wait=200, pretrain_size=200, output_file=\"py_ARF_results.csv\")\n",
    "# Run evaluation\n",
    "evaluator.evaluate(stream=stream, model=ARF, model_names=['ARF'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skmultiflow saves results to file with leading 5 lines containing configuraiton of evaluation, learner etc\n",
    "# skmultiflow also did not evaluate last 200 samples\n",
    "# for the sake of comparisson we shrink the MOA results\n",
    "# accuracy in MOA is in % and in skmultiflow fraction\n",
    "py_ARF_results = pd.read_csv('py_ARF_results.csv',skiprows=[0,1,2,3,4],index_col=False)\n",
    "py_ARF_results['mean_acc_[ARF]'] = py_ARF_results['mean_acc_[ARF]']*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Real-world scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "samples_train = dataset.drop(columns=['fault_id']).values\n",
    "labels_train  = dataset['fault_id'].to_frame().values\n",
    "\n",
    "samples_test = dataset_test.drop(columns=['fault_id']).values\n",
    "labels_test  = dataset_test['fault_id'].to_frame().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "ARF.reset()\n",
    "stream = DataStream(data=samples_train, y=labels_train)\n",
    "stream.prepare_for_use()\n",
    "\n",
    "for sample in range(len(labels_train)):\n",
    "    X, Y = stream.next_sample()\n",
    "    ARF.partial_fit(X, Y)\n",
    "\n",
    "stream_test = DataStream(data = samples_test, y = labels_test)\n",
    "stream_test.prepare_for_use()\n",
    "\n",
    "labels_test_predicted = []\n",
    "for sample in range(len(labels_test)):\n",
    "    X, Y = stream_test.next_sample()\n",
    "    labels_test_predicted.extend(ARF.predict(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      1376\n",
      "           1       0.00      0.00      0.00        57\n",
      "           2       0.00      0.00      0.00       162\n",
      "           3       0.00      0.00      0.00       378\n",
      "           4       0.00      0.00      0.00        53\n",
      "           5       0.00      0.00      0.00       190\n",
      "           6       0.00      0.00      0.00       115\n",
      "           7       0.00      0.00      0.00       690\n",
      "           8       0.00      0.00      0.00       167\n",
      "           9       0.00      0.00      0.00       449\n",
      "          10       0.00      0.00      0.00        45\n",
      "          11       0.00      0.00      0.00      1121\n",
      "          12       0.00      0.00      0.00       535\n",
      "          13       0.00      0.00      0.00       395\n",
      "          14       0.00      0.00      0.00       220\n",
      "          15       0.00      0.00      0.00       547\n",
      "          16       0.00      0.00      0.00      1071\n",
      "          17       0.00      0.00      0.00       810\n",
      "          18       0.00      0.00      0.00      1289\n",
      "          19       0.00      0.00      0.00       691\n",
      "          20       0.00      0.00      0.00       247\n",
      "          21       0.07      1.00      0.14       860\n",
      "\n",
      "    accuracy                           0.07     11468\n",
      "   macro avg       0.00      0.05      0.01     11468\n",
      "weighted avg       0.01      0.07      0.01     11468\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Classification report :\\n' + str(classification_report(labels_test, labels_test_predicted)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ARF.predict_proba(X)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
