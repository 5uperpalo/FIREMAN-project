{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ab622fa-2181-4f28-b1ca-90df96c5b344",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58c2cf06-902a-4f5a-bf75-181e7f093c0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import stumpy\n",
    "from src import common, pipeline\n",
    "from src.outlier_model import OutlierModel\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s: %(message)s', datefmt='%m/%d/%Y %I:%M:%S %p')\n",
    "logger = logging.getLogger(\"TimeSeries\")\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e38dff8-a1c2-4afb-9420-d13c2bacf93d",
   "metadata": {},
   "source": [
    "# Dataset preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "727dde3d-d032-4c83-a32f-2fe681d9abd2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "column_types_loc = \"#datasets/Colab_PowerConverter/column_types.json\"\n",
    "column_types = common.json_load(column_types_loc)\n",
    "\n",
    "target = column_types[\"target\"]\n",
    "identifier = column_types[\"identifier\"]\n",
    "cat_cols = column_types[\"categorical\"]\n",
    "measurement_label = column_types[\"measurement_label\"]\n",
    "\n",
    "data = pd.read_pickle(\n",
    "    f\"#datasets/Colab_PowerConverter/dataset.pkl\"\n",
    ")\n",
    "\n",
    "# this measurement did not have a fault (?)\n",
    "data = data[data[measurement_label]!=\"Single-Phase_Sensor_Fault\"]\n",
    "data.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# assign unique label to each measurement fault and create dictionary for easier analysis\n",
    "fault_dict = {}\n",
    "for label,i in zip(data[measurement_label].unique(), range(len(data[measurement_label].unique()))):\n",
    "    data.loc[(data[measurement_label]==label) & (data[target]==1), target] = int(i+1)\n",
    "    fault_dict[label] = int(i+1)\n",
    "\n",
    "data.drop(columns=[measurement_label], inplace=True)\n",
    "# Fill NA - 0 for numerical and 'NA' for categorical\n",
    "# categorical\n",
    "data[cat_cols] = data[cat_cols].fillna(\"NA\")\n",
    "data[cat_cols] = data[cat_cols].astype(str)\n",
    "# non-categorical\n",
    "non_cat_cols = data.drop(columns=cat_cols + [identifier]).columns.tolist()\n",
    "data[non_cat_cols] = data[non_cat_cols].fillna(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b090d7-1d8c-4881-8605-7f304a476d2f",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ae3a556-f309-459e-9f79-9948dcf2e82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = \"multiclass\"\n",
    "\n",
    "column_types_loc = \"#datasets/Colab_PowerConverter/column_types.json\"\n",
    "save_loc = \"models.dill\"\n",
    "\n",
    "parameters = {\n",
    "    \"random_state\": 1,\n",
    "    \"test_size_train\": 0.2,\n",
    "    \"test_size_valid\": 0.5,\n",
    "    \"scaler\": \"Standard\",\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d054772-b757-409c-a050-30babb843298",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of dataset classes:\n",
      "0     597599\n",
      "5      40014\n",
      "3      40001\n",
      "6      40001\n",
      "7      40001\n",
      "8      40001\n",
      "9      40001\n",
      "10     40001\n",
      "11     40001\n",
      "13     40001\n",
      "1      38971\n",
      "2      38971\n",
      "4       3166\n",
      "12      1335\n",
      "Name: fault, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abeattie/AlexDev/FIREMAN-project/venv/lib/python3.9/site-packages/pytorch_widedeep/preprocessing/tab_preprocessor.py:203: UserWarning: Continuous columns will not be normalised\n",
      "  warnings.warn(\"Continuous columns will not be normalised\")\n",
      "epoch 1:   0%|          | 0/748 [00:25<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "(\n",
    "    data_train_scaled,\n",
    "    data_valid_scaled,\n",
    "    data_test_scaled,\n",
    "    models,\n",
    ") = pipeline.train(task,data, column_types_loc, parameters, save_loc=save_loc, verbose=True, datasets=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6709ee67-c48b-49d2-b442-b58959881a49",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "predicted = pipeline.predict(data, column_types_loc, save_loc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4534f2d",
   "metadata": {},
   "source": [
    "# Outlier_model\n",
    "* outlier_model code that implementes outlier_model.predict() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c79a5e",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "start_index = 0\n",
    "end_index = 1000000\n",
    "data_test = data[start_index:end_index]\n",
    "\n",
    "outlier_key = \"f_c\"\n",
    "m = 250\n",
    "preload_size = 5000\n",
    "# plt.plot(data[40750:41250][outlier_key])\n",
    "outlier_model = OutlierModel(m=m,std_dev=5,\n",
    "                             time_series=data_test[:preload_size][outlier_key],\n",
    "                             egress=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862bf180",
   "metadata": {},
   "source": [
    "# Simulate stream of data\n",
    "## Inverse transform test dataset for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83f7bce",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "data_test = pd.DataFrame(models[\"scaler\"].inverse_transform(data_test_scaled.drop(columns=cat_cols + [identifier,target])),\n",
    "               columns=data_test_scaled.drop(columns=cat_cols + [identifier,target]).columns.values)\n",
    "data_test[[identifier,target]] = data_test_scaled[[identifier,target]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7475b9",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "data_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5317afea",
   "metadata": {},
   "source": [
    "* loading the whole DL model with preprocessors in each iteration is stupid but I wanted to send Alex at least some initial code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aade096d",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "fault = False\n",
    "for index, row in data_test[preload_size:].iterrows():\n",
    "    outlier_model.train_one(row[outlier_key])\n",
    "    fault = outlier_model.predict_one(index)\n",
    "    if index % 10000 == 0:\n",
    "        print(f\"Current Global index: {index}\")\n",
    "    if not fault:\n",
    "        print(\"fault start\")\n",
    "    else:\n",
    "        predicted = pipeline.predict(row, column_types_loc, save_loc)\n",
    "        # print(\"fault continues\")\n",
    "        if predicted == 0:\n",
    "            fault = False\n",
    "            print(\"fault ended\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,8))\n",
    "\n",
    "plt.plot(outlier_model.max_val,'b-',\n",
    "         outlier_model.max_mean,'r-',\n",
    "         outlier_model.max_std_dev,'g-')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,8))\n",
    "plt.plot(data_test[\"fault\"])\n",
    "plt.title(f\"Detection Method: Anomaly\")\n",
    "for i in outlier_model.anomalies:\n",
    "    plt.axvline(x=i,color='r')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}