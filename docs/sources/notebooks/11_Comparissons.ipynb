{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "# to save results to data directory\n",
    "module_path = \"..\"\n",
    "if module_path not in sys.path:\n",
    "    sys.path.insert(1, module_path)\n",
    "# increase displayed columns in jupyter notebook\n",
    "pd.set_option(\"display.max_columns\", 200)\n",
    "pd.set_option(\"display.max_rows\", 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-10 22:09:28.218228: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-01-10 22:09:28.218387: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import dill\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import lightgbm as lgbm\n",
    "import h2o\n",
    "from h2o.automl import H2OAutoML\n",
    "\n",
    "from pytorch_widedeep.dataloaders import DataLoaderImbalanced, DataLoaderDefault\n",
    "from pytorch_widedeep.preprocessing import TabPreprocessor\n",
    "from pytorch_widedeep.training import Trainer\n",
    "from pytorch_widedeep.models import TabMlp, WideDeep\n",
    "from pytorch_widedeep.bayesian_models import BayesianTabMlp\n",
    "from pytorch_widedeep.models.transformers.saint import SAINT\n",
    "from pytorch_widedeep.callbacks import (\n",
    "    EarlyStopping,\n",
    "    ModelCheckpoint,\n",
    "    LRHistory,\n",
    "    RayTuneReporter,\n",
    ")\n",
    "from pytorch_widedeep.initializers import (\n",
    "    KaimingNormal,\n",
    "    KaimingUniform,\n",
    "    XavierNormal,\n",
    "    XavierUniform,\n",
    "    Normal,\n",
    "    Uniform,\n",
    ")\n",
    "from pytorch_widedeep import Tab2Vec\n",
    "from pytorch_widedeep.optim import RAdam\n",
    "import torch\n",
    "from torch.optim import Adam, SGD, lr_scheduler#, NAdam\n",
    "\n",
    "from ray import tune\n",
    "from ray.tune.schedulers import AsyncHyperBandScheduler\n",
    "from ray.tune import JupyterNotebookReporter\n",
    "from ray.tune.integration.wandb import WandbLoggerCallback, wandb_mixin\n",
    "from ray.tune.logger import DEFAULT_LOGGERS\n",
    "import wandb\n",
    "\n",
    "import src.utils as utils\n",
    "import src.common as common\n",
    "\n",
    "import tracemalloc\n",
    "tracemalloc.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**identifiers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "column_types = common.json_load(\"#datasets/Colab_PowerConverter/column_types.json\")\n",
    "target = column_types[\"target\"]\n",
    "identifier = column_types[\"identifier\"]\n",
    "measurement_label = column_types[\"measurement_label\"]\n",
    "\n",
    "parameters = {\n",
    "    \"random_state\": 1,\n",
    "    \"valid_size\": 0.2,\n",
    "    \"test_size\": 0.5,\n",
    "    \"scaler_mapper_def\": {\n",
    "        \"target_col\": None,\n",
    "        \"identifier_col\": None,\n",
    "        \"cont_cols\": StandardScaler,\n",
    "    },\n",
    "}\n",
    "\n",
    "valid_size = parameters[\"valid_size\"]\n",
    "test_size = parameters[\"test_size\"]\n",
    "scaler_mapper_def = parameters[\"scaler_mapper_def\"]\n",
    "random_state = parameters[\"random_state\"]\n",
    "test_n_valid_combined = True\n",
    "task = \"multiclass\" #(or \"binary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"#datasets/Colab_PowerConverter/dataset.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this measurement did not have a fault (?)\n",
    "df = df[df[measurement_label]!=\"Single-Phase_Sensor_Fault\"]\n",
    "df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fault_dict = {}\n",
    "for label,i in zip(df[measurement_label].unique(), range(len(df[measurement_label].unique()))):\n",
    "    df.loc[(df[measurement_label]==label) & (df[target]==1), target] = int(i+1)\n",
    "    fault_dict[label] = int(i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     597599\n",
       "5      40014\n",
       "3      40001\n",
       "6      40001\n",
       "7      40001\n",
       "8      40001\n",
       "9      40001\n",
       "10     40001\n",
       "11     40001\n",
       "13     40001\n",
       "1      38971\n",
       "2      38971\n",
       "4       3166\n",
       "12      1335\n",
       "Name: fault, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# imbalance of the classes\n",
    "df[target].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Damping-320': 1,\n",
       " 'Damping-32000': 2,\n",
       " 'Inertia-1.2': 3,\n",
       " 'LL_Fault': 4,\n",
       " 'Three-Phase_Sensor_Fault': 5,\n",
       " 'Weak_Grid-4_5_mH': 6,\n",
       " 'Weak_Grid-1_5_mH': 7,\n",
       " 'Damping-3200': 8,\n",
       " 'Inertia-0.2': 9,\n",
       " 'Inertia-2': 10,\n",
       " 'Single_Phase_Sag': 11,\n",
       " 'Three_Phase_Grid_Fault': 12,\n",
       " 'Weak_Grid-7_5_mH': 13}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fault_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=[measurement_label], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_valid = train_test_split(df, test_size=valid_size, stratify=df[target], random_state=random_state)\n",
    "df_valid, df_test = train_test_split(df_valid, test_size=test_size, stratify=df_valid[target], random_state=random_state)\n",
    "\n",
    "df_train.reset_index(inplace=True, drop=True)\n",
    "df_valid.reset_index(inplace=True, drop=True)\n",
    "df_test.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_cols = df.drop(columns=[target,identifier]).columns.values\n",
    "scaler = utils.scaler_mapper(\n",
    "    cont_cols=cont_cols,\n",
    "    target_col=target,\n",
    "    identifier=identifier,\n",
    "    scaler_mapper_def=scaler_mapper_def,\n",
    ")\n",
    "\n",
    "df_train_scaled = scaler.fit_transform(df_train)\n",
    "df_test_scaled = scaler.transform(df_test)\n",
    "df_valid_scaled = scaler.transform(df_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## H2O AutoML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th style=\"text-align: right;\">        f_c</th><th style=\"text-align: right;\">         P</th><th style=\"text-align: right;\">  m_d</th><th style=\"text-align: right;\">  m_q</th><th style=\"text-align: right;\">     theta</th><th style=\"text-align: right;\">  P_ref</th><th style=\"text-align: right;\">  V_DC</th><th style=\"text-align: right;\">   V_phaseA</th><th style=\"text-align: right;\">   V_phaseB</th><th style=\"text-align: right;\">   V_phaseC</th><th style=\"text-align: right;\">   I_phaseA</th><th style=\"text-align: right;\">    I_phaseB</th><th style=\"text-align: right;\">    I_phaseC</th><th style=\"text-align: right;\">  fault</th><th style=\"text-align: right;\">       sample_id</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td style=\"text-align: right;\">  0.0764099</td><td style=\"text-align: right;\">-0.0644905</td><td style=\"text-align: right;\">    0</td><td style=\"text-align: right;\">    0</td><td style=\"text-align: right;\"> 0.103179 </td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">     0</td><td style=\"text-align: right;\"> 0.0136144 </td><td style=\"text-align: right;\">-1.25391   </td><td style=\"text-align: right;\"> 1.23911   </td><td style=\"text-align: right;\"> 0.00159406</td><td style=\"text-align: right;\">-0.002035   </td><td style=\"text-align: right;\"> 0.000468371</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">     1.06966e+06</td></tr>\n",
       "<tr><td style=\"text-align: right;\">  0.0764093</td><td style=\"text-align: right;\">-0.06449  </td><td style=\"text-align: right;\">    0</td><td style=\"text-align: right;\">    0</td><td style=\"text-align: right;\"> 0.670499 </td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">     0</td><td style=\"text-align: right;\">-1.21108   </td><td style=\"text-align: right;\">-0.0848593 </td><td style=\"text-align: right;\"> 1.28534   </td><td style=\"text-align: right;\">-0.0250353 </td><td style=\"text-align: right;\"> 0.0462085  </td><td style=\"text-align: right;\">-0.0228063  </td><td style=\"text-align: right;\">      7</td><td style=\"text-align: right;\">614815          </td></tr>\n",
       "<tr><td style=\"text-align: right;\">  0.0764093</td><td style=\"text-align: right;\">-0.06449  </td><td style=\"text-align: right;\">    0</td><td style=\"text-align: right;\">    0</td><td style=\"text-align: right;\"> 1.03229  </td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">     0</td><td style=\"text-align: right;\">-0.717513  </td><td style=\"text-align: right;\">-0.727768  </td><td style=\"text-align: right;\"> 1.4383    </td><td style=\"text-align: right;\">-0.0400163 </td><td style=\"text-align: right;\"> 0.0394656  </td><td style=\"text-align: right;\"> 0.000842797</td><td style=\"text-align: right;\">      7</td><td style=\"text-align: right;\">630845          </td></tr>\n",
       "<tr><td style=\"text-align: right;\">  0.0764093</td><td style=\"text-align: right;\">-0.06449  </td><td style=\"text-align: right;\">    0</td><td style=\"text-align: right;\">    0</td><td style=\"text-align: right;\">-0.0804041</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">     0</td><td style=\"text-align: right;\">-1.25339   </td><td style=\"text-align: right;\"> 1.24611   </td><td style=\"text-align: right;\">-0.00229003</td><td style=\"text-align: right;\"> 0.00109732</td><td style=\"text-align: right;\">-0.000931532</td><td style=\"text-align: right;\">-0.00018652 </td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">741526          </td></tr>\n",
       "<tr><td style=\"text-align: right;\">  0.0766861</td><td style=\"text-align: right;\">-0.0647668</td><td style=\"text-align: right;\">    0</td><td style=\"text-align: right;\">    0</td><td style=\"text-align: right;\"> 0.611718 </td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">     0</td><td style=\"text-align: right;\"> 0.00023845</td><td style=\"text-align: right;\">-0.00149468</td><td style=\"text-align: right;\"> 0.00126347</td><td style=\"text-align: right;\"> 0.035414  </td><td style=\"text-align: right;\">-0.00863098 </td><td style=\"text-align: right;\">-0.0292607  </td><td style=\"text-align: right;\">      5</td><td style=\"text-align: right;\">452148          </td></tr>\n",
       "<tr><td style=\"text-align: right;\">-15.9596   </td><td style=\"text-align: right;\">15.978    </td><td style=\"text-align: right;\">    0</td><td style=\"text-align: right;\">    0</td><td style=\"text-align: right;\">-3.04602  </td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">     0</td><td style=\"text-align: right;\"> 0.53551   </td><td style=\"text-align: right;\"> 0.89073   </td><td style=\"text-align: right;\">-1.42061   </td><td style=\"text-align: right;\"> 0.00213073</td><td style=\"text-align: right;\"> 0.0130485  </td><td style=\"text-align: right;\">-0.0164733  </td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">     1.00344e+06</td></tr>\n",
       "<tr><td style=\"text-align: right;\">  0.0766861</td><td style=\"text-align: right;\">-0.0647668</td><td style=\"text-align: right;\">    0</td><td style=\"text-align: right;\">    0</td><td style=\"text-align: right;\"> 1.24128  </td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">     0</td><td style=\"text-align: right;\"> 0.00023845</td><td style=\"text-align: right;\">-0.00149468</td><td style=\"text-align: right;\"> 0.00126347</td><td style=\"text-align: right;\">-0.0308137 </td><td style=\"text-align: right;\">-0.0729725  </td><td style=\"text-align: right;\"> 0.112734   </td><td style=\"text-align: right;\">      5</td><td style=\"text-align: right;\">479973          </td></tr>\n",
       "<tr><td style=\"text-align: right;\"> -0.0550365</td><td style=\"text-align: right;\">-0.05134  </td><td style=\"text-align: right;\">    0</td><td style=\"text-align: right;\">    0</td><td style=\"text-align: right;\">-2.16788  </td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">     0</td><td style=\"text-align: right;\"> 1.21972   </td><td style=\"text-align: right;\">-1.28017   </td><td style=\"text-align: right;\"> 0.0697169 </td><td style=\"text-align: right;\"> 0.0838388 </td><td style=\"text-align: right;\">-0.00528121 </td><td style=\"text-align: right;\">-0.0857018  </td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\"> 75794          </td></tr>\n",
       "<tr><td style=\"text-align: right;\">  0.0764147</td><td style=\"text-align: right;\">-0.064495 </td><td style=\"text-align: right;\">    0</td><td style=\"text-align: right;\">    0</td><td style=\"text-align: right;\"> 0.781905 </td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">     0</td><td style=\"text-align: right;\"> 1.32264   </td><td style=\"text-align: right;\">-1.16804   </td><td style=\"text-align: right;\">-0.144324  </td><td style=\"text-align: right;\">-0.00410528</td><td style=\"text-align: right;\">-0.0110269  </td><td style=\"text-align: right;\"> 0.0164344  </td><td style=\"text-align: right;\">      6</td><td style=\"text-align: right;\">539733          </td></tr>\n",
       "<tr><td style=\"text-align: right;\">  0.0764093</td><td style=\"text-align: right;\">-0.06449  </td><td style=\"text-align: right;\">    0</td><td style=\"text-align: right;\">    0</td><td style=\"text-align: right;\">-3.30012  </td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">     0</td><td style=\"text-align: right;\">-0.80531   </td><td style=\"text-align: right;\"> 1.43398   </td><td style=\"text-align: right;\">-0.634138  </td><td style=\"text-align: right;\"> 0.00130697</td><td style=\"text-align: right;\">-0.00087162 </td><td style=\"text-align: right;\">-0.000480115</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">     1.0339e+06 </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h2o_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321 . connected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O_cluster_uptime:</td>\n",
       "<td>26 mins 38 secs</td></tr>\n",
       "<tr><td>H2O_cluster_timezone:</td>\n",
       "<td>Europe/Madrid</td></tr>\n",
       "<tr><td>H2O_data_parsing_timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O_cluster_version:</td>\n",
       "<td>3.34.0.7</td></tr>\n",
       "<tr><td>H2O_cluster_version_age:</td>\n",
       "<td>16 days </td></tr>\n",
       "<tr><td>H2O_cluster_name:</td>\n",
       "<td>H2O_from_python_palo_ku3umh</td></tr>\n",
       "<tr><td>H2O_cluster_total_nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O_cluster_free_memory:</td>\n",
       "<td>2.520 Gb</td></tr>\n",
       "<tr><td>H2O_cluster_total_cores:</td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O_cluster_allowed_cores:</td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O_cluster_status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O_connection_url:</td>\n",
       "<td>http://localhost:54321</td></tr>\n",
       "<tr><td>H2O_connection_proxy:</td>\n",
       "<td>{\"http\": null, \"https\": null}</td></tr>\n",
       "<tr><td>H2O_internal_security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>H2O_API_Extensions:</td>\n",
       "<td>Amazon S3, XGBoost, Algos, AutoML, Core V3, TargetEncoder, Core V4</td></tr>\n",
       "<tr><td>Python_version:</td>\n",
       "<td>3.8.5 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  ------------------------------------------------------------------\n",
       "H2O_cluster_uptime:         26 mins 38 secs\n",
       "H2O_cluster_timezone:       Europe/Madrid\n",
       "H2O_data_parsing_timezone:  UTC\n",
       "H2O_cluster_version:        3.34.0.7\n",
       "H2O_cluster_version_age:    16 days\n",
       "H2O_cluster_name:           H2O_from_python_palo_ku3umh\n",
       "H2O_cluster_total_nodes:    1\n",
       "H2O_cluster_free_memory:    2.520 Gb\n",
       "H2O_cluster_total_cores:    8\n",
       "H2O_cluster_allowed_cores:  8\n",
       "H2O_cluster_status:         locked, healthy\n",
       "H2O_connection_url:         http://localhost:54321\n",
       "H2O_connection_proxy:       {\"http\": null, \"https\": null}\n",
       "H2O_internal_security:      False\n",
       "H2O_API_Extensions:         Amazon S3, XGBoost, Algos, AutoML, Core V3, TargetEncoder, Core V4\n",
       "Python_version:             3.8.5 final\n",
       "--------------------------  ------------------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data into H2O format\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/palo/miniconda3/lib/python3.8/site-packages/h2o/h2o.py:121: ResourceWarning: unclosed file <_io.BufferedReader name='/tmp/tmpq6_1h7s5.csv'>\n",
      "  return h2oconn.request(endpoint, data=data, json=json, filename=filename, save_to=save_to)\n",
      "Object allocated at (most recent call last):\n",
      "  File \"/home/palo/miniconda3/lib/python3.8/site-packages/h2o/backend/connection.py\", lineno 720\n",
      "    return {os.path.basename(absfilename): open(absfilename, \"rb\")}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "Parse progress: |"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/palo/miniconda3/lib/python3.8/site-packages/h2o/h2o.py:121: ResourceWarning: unclosed file <_io.BufferedReader name='/tmp/tmpkfhzlt8y.csv'>\n",
      "  return h2oconn.request(endpoint, data=data, json=json, filename=filename, save_to=save_to)\n",
      "Object allocated at (most recent call last):\n",
      "  File \"/home/palo/miniconda3/lib/python3.8/site-packages/h2o/backend/connection.py\", lineno 720\n",
      "    return {os.path.basename(absfilename): open(absfilename, \"rb\")}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "████████████████████████████████████████████████████████████████| (done) 100%\n",
      "Parse progress: |"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/palo/miniconda3/lib/python3.8/site-packages/h2o/h2o.py:121: ResourceWarning: unclosed file <_io.BufferedReader name='/tmp/tmpchp3xzlo.csv'>\n",
      "  return h2oconn.request(endpoint, data=data, json=json, filename=filename, save_to=save_to)\n",
      "Object allocated at (most recent call last):\n",
      "  File \"/home/palo/miniconda3/lib/python3.8/site-packages/h2o/backend/connection.py\", lineno 720\n",
      "    return {os.path.basename(absfilename): open(absfilename, \"rb\")}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "████████████████████████████████████████████████████████████████| (done) 100%\n",
      "AutoML progress: |\n",
      "23:33:05.829: _train param, Dropping bad and constant columns: [P_ref, V_DC, m_d, m_q]\n",
      "\n",
      "██████████████████████\n",
      "23:43:03.261: _train param, Dropping bad and constant columns: [P_ref, V_DC, m_d, m_q]\n",
      "\n",
      "█████████████████████████████\n",
      "23:57:25.774: _train param, Dropping bad and constant columns: [P_ref, V_DC, m_d, m_q]\n",
      "\n",
      "Failed polling AutoML progress log: HTTP 500 Server Error:\n",
      "<html>\n",
      "<head>\n",
      "<meta http-equiv=\"Content-Type\" content=\"text/html;charset=utf-8\"/>\n",
      "<title>Error 500 Server Error</title>\n",
      "</head>\n",
      "<body><h2>HTTP ERROR 500</h2>\n",
      "<p>Problem accessing /99/AutoML/AutoML_4_20220106_233305@@fault. Reason:\n",
      "<pre>    Server Error</pre></p><h3>Caused by:</h3><pre>java.lang.OutOfMemoryError: Java heap space\n",
      "</pre>\n",
      "\n",
      "</body>\n",
      "</html>\n",
      "\n",
      "█\n",
      "23:57:46.590: GBM_1_AutoML_4_20220106_233305 [GBM def_5] failed: DistributedException from /127.0.0.1:54321: 'Java heap space', caused by java.lang.OutOfMemoryError: Java heap space\n",
      "23:57:46.601: _train param, Dropping unused columns: [P_ref, V_DC, m_d, m_q]\n",
      "\n",
      "███████████| (done) 100%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/palo/miniconda3/lib/python3.8/site-packages/h2o/h2o.py:121: ResourceWarning: unclosed file <_io.BufferedReader name='/tmp/tmpu8jj_eou.csv'>\n",
      "  return h2oconn.request(endpoint, data=data, json=json, filename=filename, save_to=save_to)\n",
      "Object allocated at (most recent call last):\n",
      "  File \"/home/palo/miniconda3/lib/python3.8/site-packages/h2o/backend/connection.py\", lineno 720\n",
      "    return {os.path.basename(absfilename): open(absfilename, \"rb\")}\n"
     ]
    },
    {
     "ename": "H2OResponseError",
     "evalue": "Server error java.lang.IllegalArgumentException:\n  Error: Total input file size of  436  B is much larger than total cluster memory of Zero  , please use either a larger cluster or smaller data.\n  Request: POST /3/Parse\n    data: {'destination_frame': 'AutoML_4_20220106_233305_leaderboard', 'parse_type': 'CSV', 'separator': '44', 'check_header': '1', 'number_columns': '6', 'chunk_size': '4194304', 'delete_on_done': 'True', 'blocking': 'False', 'column_types': '[\"string\",\"string\",\"double\",\"double\",\"double\",\"double\"]', 'single_quotes': 'False', 'escapechar': '0', 'column_names': '[\"\",\"model_id\",\"mean_per_class_error\",\"logloss\",\"rmse\",\"mse\"]', 'source_frames': '[\"upload_8a591791a2d0d184c45385b51edf4c66\"]'}\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mH2OResponseError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1835/2320084112.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# Run it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m _ = aml.train(\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcont_cols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/h2o/automl/_estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, x, y, training_frame, fold_column, weights_column, validation_frame, leaderboard_frame, blending_frame)\u001b[0m\n\u001b[1;32m    594\u001b[0m             \u001b[0mpoll_updates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_job\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/h2o/automl/_estimator.py\u001b[0m in \u001b[0;36m_fetch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    623\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m         \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_fetch_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_leader_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'leader_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_leaderboard\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'leaderboard'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/h2o/automl/_base.py\u001b[0m in \u001b[0;36m_fetch_state\u001b[0;34m(aml_id, properties, verbosity)\u001b[0m\n\u001b[1;32m    273\u001b[0m     \u001b[0mleaderboard\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshould_fetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'leaderboard'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m         \u001b[0mleaderboard\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_fetch_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_json\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'leaderboard_table'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproject_name\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"_leaderboard\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprogress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m     \u001b[0mevent_log\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/h2o/automl/_base.py\u001b[0m in \u001b[0;36m_fetch_table\u001b[0;34m(table, key, progress_bar)\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0mH2OJob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__PROGRESS_BAR__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprogress_bar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;31m# Parse leaderboard H2OTwoDimTable & return as an H2OFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m         \u001b[0mfr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh2o\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mH2OFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcell_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestination_frame\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcol_header\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcol_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mh2o\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# removing index and reassign id to ensure persistence on backend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/h2o/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, python_obj, destination_frame, header, separator, column_names, column_types, na_strings, skipped_columns)\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_frame\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m  \u001b[0;31m# Indicate that this is an actual frame, allowing typechecks to be made\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpython_obj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m             self._upload_python_object(python_obj, destination_frame, header, separator,\n\u001b[0m\u001b[1;32m    111\u001b[0m                                        column_names, column_types, na_strings, skipped_columns)\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/h2o/frame.py\u001b[0m in \u001b[0;36m_upload_python_object\u001b[0;34m(self, python_obj, destination_frame, header, separator, column_names, column_types, na_strings, skipped_columns)\u001b[0m\n\u001b[1;32m    150\u001b[0m             \u001b[0mcsv_writer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriterows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_to_write\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0mtmp_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# close the streams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_upload_parse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestination_frame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseparator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_strings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipped_columns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_path\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# delete the tmp file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/h2o/frame.py\u001b[0m in \u001b[0;36m_upload_parse\u001b[0;34m(self, path, destination_frame, header, sep, column_names, column_types, na_strings, skipped_columns, quotechar, escapechar)\u001b[0m\n\u001b[1;32m    465\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh2o\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"POST /3/PostFile\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m         \u001b[0mrawkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"destination_frame\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 467\u001b[0;31m         self._parse(rawkey, destination_frame, header, sep, column_names, column_types, na_strings, skipped_columns,\n\u001b[0m\u001b[1;32m    468\u001b[0m                     quotechar=quotechar, escapechar=escapechar)\n\u001b[1;32m    469\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/h2o/frame.py\u001b[0m in \u001b[0;36m_parse\u001b[0;34m(self, rawkey, destination_frame, header, separator, column_names, column_types, na_strings, skipped_columns, custom_non_data_line_markers, partition_by, quotechar, escapechar)\u001b[0m\n\u001b[1;32m    475\u001b[0m         setup = h2o.parse_setup(rawkey, destination_frame, header, separator, column_names, column_types, na_strings,\n\u001b[1;32m    476\u001b[0m                                 skipped_columns, custom_non_data_line_markers, partition_by, quotechar, escapechar)\n\u001b[0;32m--> 477\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msetup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/h2o/frame.py\u001b[0m in \u001b[0;36m_parse_raw\u001b[0;34m(self, setup)\u001b[0m\n\u001b[1;32m    504\u001b[0m         \u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'source_frames'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_quoted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msrc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msetup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'source_frames'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 506\u001b[0;31m         \u001b[0mH2OJob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh2o\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"POST /3/Parse\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Parse\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    507\u001b[0m         \u001b[0;31m# Need to return a Frame here for nearly all callers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m         \u001b[0;31m# ... but job stats returns only a dest_key, requiring another REST call to get nrow/ncol\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/h2o/h2o.py\u001b[0m in \u001b[0;36mapi\u001b[0;34m(endpoint, data, json, filename, save_to)\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;31m# type checks are performed in H2OConnection class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0m_check_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mh2oconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msave_to\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/h2o/backend/connection.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, endpoint, data, json, filename, save_to)\u001b[0m\n\u001b[1;32m    479\u001b[0m                 \u001b[0msave_to\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msave_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_end_transaction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 481\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_to\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    482\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConnectionError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHTTPError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/h2o/backend/connection.py\u001b[0m in \u001b[0;36m_process_response\u001b[0;34m(response, save_to)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstatus_code\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;36m400\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m404\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m412\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH2OErrorV3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow_stacktrace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mH2OResponseError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m         \u001b[0;31m# Server errors (notably 500 = \"Server Error\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mH2OResponseError\u001b[0m: Server error java.lang.IllegalArgumentException:\n  Error: Total input file size of  436  B is much larger than total cluster memory of Zero  , please use either a larger cluster or smaller data.\n  Request: POST /3/Parse\n    data: {'destination_frame': 'AutoML_4_20220106_233305_leaderboard', 'parse_type': 'CSV', 'separator': '44', 'check_header': '1', 'number_columns': '6', 'chunk_size': '4194304', 'delete_on_done': 'True', 'blocking': 'False', 'column_types': '[\"string\",\"string\",\"double\",\"double\",\"double\",\"double\"]', 'single_quotes': 'False', 'escapechar': '0', 'column_names': '[\"\",\"model_id\",\"mean_per_class_error\",\"logloss\",\"rmse\",\"mse\"]', 'source_frames': '[\"upload_8a591791a2d0d184c45385b51edf4c66\"]'}\n"
     ]
    }
   ],
   "source": [
    "# initialize H2O\n",
    "h2o.init(log_dir=\"h2o_logs\", log_level=\"WARN\")\n",
    "\n",
    "# read as h2o file\n",
    "print(\"Reading data into H2O format\")\n",
    "h2o_train = h2o.H2OFrame(df_train_scaled)\n",
    "h2o_valid = h2o.H2OFrame(df_valid_scaled)\n",
    "h2o_test = h2o.H2OFrame(df_test_scaled)\n",
    "\n",
    "# For binary classification, response should be a factor\n",
    "h2o_train[target] = h2o_train[target].asfactor()\n",
    "h2o_valid[target] = h2o_valid[target].asfactor()\n",
    "h2o_test[target] = h2o_test[target].asfactor()\n",
    "\n",
    "# Define AML task\n",
    "aml = H2OAutoML(seed=random_state, max_runtime_secs=1800)\n",
    "\n",
    "# over/under sample for classification tasks\n",
    "aml.balance_classes = True\n",
    "\n",
    "# Run it\n",
    "_ = aml.train(\n",
    "    x=list(cont_cols),\n",
    "    y=target,\n",
    "    training_frame=h2o_train,\n",
    "    leaderboard_frame=h2o_valid,\n",
    ")\n",
    "\n",
    "m = aml.get_best_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/palo/miniconda3/lib/python3.8/site-packages/h2o/h2o.py:121: ResourceWarning: unclosed file <_io.BufferedReader name='/tmp/tmpd93uewig.csv'>\n",
      "  return h2oconn.request(endpoint, data=data, json=json, filename=filename, save_to=save_to)\n",
      "Object allocated at (most recent call last):\n",
      "  File \"/home/palo/miniconda3/lib/python3.8/site-packages/h2o/backend/connection.py\", lineno 720\n",
      "    return {os.path.basename(absfilename): open(absfilename, \"rb\")}\n"
     ]
    },
    {
     "ename": "H2OResponseError",
     "evalue": "Server error java.lang.IllegalArgumentException:\n  Error: Total input file size of  577  B is much larger than total cluster memory of Zero  , please use either a larger cluster or smaller data.\n  Request: POST /3/Parse\n    data: {'destination_frame': 'AutoML_4_20220106_233305_custom_leaderboard', 'parse_type': 'CSV', 'separator': '44', 'check_header': '1', 'number_columns': '9', 'chunk_size': '4194304', 'delete_on_done': 'True', 'blocking': 'False', 'column_types': '[\"string\",\"string\",\"double\",\"double\",\"double\",\"double\",\"long\",\"double\",\"string\"]', 'single_quotes': 'False', 'escapechar': '0', 'column_names': '[\"\",\"model_id\",\"mean_per_class_error\",\"logloss\",\"rmse\",\"mse\",\"training_time_ms\",\"predict_time_per_row_ms\",\"algo\"]', 'source_frames': '[\"upload_b2adc2f5455e83f4133392c81f524ffb\"]'}\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mH2OResponseError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1835/3835008652.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh2o\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautoml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_leaderboard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextra_columns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ALL\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/h2o/automl/autoh2o.py\u001b[0m in \u001b[0;36mget_leaderboard\u001b[0;34m(aml, extra_columns)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \"\"\"\n\u001b[1;32m     44\u001b[0m     \u001b[0massert_is_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH2OAutoML\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH2OAutoMLOutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_fetch_leaderboard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextra_columns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/h2o/automl/_base.py\u001b[0m in \u001b[0;36m_fetch_leaderboard\u001b[0;34m(aml_id, extensions)\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh2o\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"GET /99/Leaderboards/%s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0maml_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextensions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextensions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m     \u001b[0mdest_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'project_name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'@'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"_custom_leaderboard\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_fetch_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'table'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdest_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprogress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/h2o/automl/_base.py\u001b[0m in \u001b[0;36m_fetch_table\u001b[0;34m(table, key, progress_bar)\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0mH2OJob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__PROGRESS_BAR__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprogress_bar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;31m# Parse leaderboard H2OTwoDimTable & return as an H2OFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m         \u001b[0mfr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh2o\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mH2OFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcell_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestination_frame\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcol_header\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcol_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mh2o\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# removing index and reassign id to ensure persistence on backend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/h2o/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, python_obj, destination_frame, header, separator, column_names, column_types, na_strings, skipped_columns)\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_frame\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m  \u001b[0;31m# Indicate that this is an actual frame, allowing typechecks to be made\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpython_obj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m             self._upload_python_object(python_obj, destination_frame, header, separator,\n\u001b[0m\u001b[1;32m    111\u001b[0m                                        column_names, column_types, na_strings, skipped_columns)\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/h2o/frame.py\u001b[0m in \u001b[0;36m_upload_python_object\u001b[0;34m(self, python_obj, destination_frame, header, separator, column_names, column_types, na_strings, skipped_columns)\u001b[0m\n\u001b[1;32m    150\u001b[0m             \u001b[0mcsv_writer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriterows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_to_write\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0mtmp_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# close the streams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_upload_parse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestination_frame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseparator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_strings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipped_columns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_path\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# delete the tmp file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/h2o/frame.py\u001b[0m in \u001b[0;36m_upload_parse\u001b[0;34m(self, path, destination_frame, header, sep, column_names, column_types, na_strings, skipped_columns, quotechar, escapechar)\u001b[0m\n\u001b[1;32m    465\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh2o\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"POST /3/PostFile\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m         \u001b[0mrawkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"destination_frame\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 467\u001b[0;31m         self._parse(rawkey, destination_frame, header, sep, column_names, column_types, na_strings, skipped_columns,\n\u001b[0m\u001b[1;32m    468\u001b[0m                     quotechar=quotechar, escapechar=escapechar)\n\u001b[1;32m    469\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/h2o/frame.py\u001b[0m in \u001b[0;36m_parse\u001b[0;34m(self, rawkey, destination_frame, header, separator, column_names, column_types, na_strings, skipped_columns, custom_non_data_line_markers, partition_by, quotechar, escapechar)\u001b[0m\n\u001b[1;32m    475\u001b[0m         setup = h2o.parse_setup(rawkey, destination_frame, header, separator, column_names, column_types, na_strings,\n\u001b[1;32m    476\u001b[0m                                 skipped_columns, custom_non_data_line_markers, partition_by, quotechar, escapechar)\n\u001b[0;32m--> 477\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msetup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/h2o/frame.py\u001b[0m in \u001b[0;36m_parse_raw\u001b[0;34m(self, setup)\u001b[0m\n\u001b[1;32m    504\u001b[0m         \u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'source_frames'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_quoted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msrc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msetup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'source_frames'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 506\u001b[0;31m         \u001b[0mH2OJob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh2o\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"POST /3/Parse\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Parse\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    507\u001b[0m         \u001b[0;31m# Need to return a Frame here for nearly all callers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m         \u001b[0;31m# ... but job stats returns only a dest_key, requiring another REST call to get nrow/ncol\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/h2o/h2o.py\u001b[0m in \u001b[0;36mapi\u001b[0;34m(endpoint, data, json, filename, save_to)\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;31m# type checks are performed in H2OConnection class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0m_check_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mh2oconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msave_to\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/h2o/backend/connection.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, endpoint, data, json, filename, save_to)\u001b[0m\n\u001b[1;32m    479\u001b[0m                 \u001b[0msave_to\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msave_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_end_transaction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 481\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_to\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    482\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConnectionError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHTTPError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/h2o/backend/connection.py\u001b[0m in \u001b[0;36m_process_response\u001b[0;34m(response, save_to)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstatus_code\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;36m400\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m404\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m412\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH2OErrorV3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow_stacktrace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mH2OResponseError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m         \u001b[0;31m# Server errors (notably 500 = \"Server Error\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mH2OResponseError\u001b[0m: Server error java.lang.IllegalArgumentException:\n  Error: Total input file size of  577  B is much larger than total cluster memory of Zero  , please use either a larger cluster or smaller data.\n  Request: POST /3/Parse\n    data: {'destination_frame': 'AutoML_4_20220106_233305_custom_leaderboard', 'parse_type': 'CSV', 'separator': '44', 'check_header': '1', 'number_columns': '9', 'chunk_size': '4194304', 'delete_on_done': 'True', 'blocking': 'False', 'column_types': '[\"string\",\"string\",\"double\",\"double\",\"double\",\"double\",\"long\",\"double\",\"string\"]', 'single_quotes': 'False', 'escapechar': '0', 'column_names': '[\"\",\"model_id\",\"mean_per_class_error\",\"logloss\",\"rmse\",\"mse\",\"training_time_ms\",\"predict_time_per_row_ms\",\"algo\"]', 'source_frames': '[\"upload_b2adc2f5455e83f4133392c81f524ffb\"]'}\n"
     ]
    }
   ],
   "source": [
    "lb = h2o.automl.get_leaderboard(aml, extra_columns=\"ALL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This H2OFrame is empty.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(lb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leaderboard, show and save\n",
    "lb = h2o.automl.get_leaderboard(aml, extra_columns=\"ALL\")\n",
    "print(lb)\n",
    "# save results\n",
    "h2o.export_file(lb, path=\"h2o_logs/leaderboard.csv\"), force=True)\n",
    "\n",
    "print(m.model_performance(h2o_valid))\n",
    "\n",
    "# MOJO is h2o version agnostic\n",
    "model_path = os.path.join(session_dir_path, \"bestmodel.zip\")\n",
    "m.save_mojo(\"h2o_logs/bestmodel.zip\")\n",
    "\n",
    "predictions = m.predict(h2o_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metric and objective functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def focal_loss_lgb(y_pred, dtrain, alpha, gamma, num_class):\n",
    "    \"\"\"\n",
    "    Focal Loss for lightgbm\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    y_pred: numpy.ndarray\n",
    "        array with the predictions\n",
    "    dtrain: lightgbm.Dataset\n",
    "    alpha, gamma: float\n",
    "        See original paper https://arxiv.org/pdf/1708.02002.pdf\n",
    "    num_class: int\n",
    "        number of classes\n",
    "    \"\"\"\n",
    "    a,g = alpha, gamma\n",
    "    y_true = dtrain.label\n",
    "    # N observations x num_class arrays\n",
    "    y_true = np.eye(num_class)[y_true.astype('int')]\n",
    "    y_pred = y_pred.reshape(-1,num_class, order='F')\n",
    "    # alpha and gamma multiplicative factors with BCEWithLogitsLoss\n",
    "    def fl(x,t):\n",
    "        p = 1/(1+np.exp(-x))\n",
    "        return -( a*t + (1-a)*(1-t) ) * (( 1 - ( t*p + (1-t)*(1-p)) )**g) * ( t*np.log(p)+(1-t)*np.log(1-p) )\n",
    "    partial_fl = lambda x: fl(x, y_true)\n",
    "    grad = derivative(partial_fl, y_pred, n=1, dx=1e-6)\n",
    "    hess = derivative(partial_fl, y_pred, n=2, dx=1e-6)\n",
    "    # flatten in column-major (Fortran-style) order\n",
    "    return grad.flatten('F'), hess.flatten('F')\n",
    "\n",
    "def focal_loss_lgb_eval_error(y_pred, dtrain, alpha, gamma, num_class):\n",
    "    \"\"\"\n",
    "    Focal Loss for lightgbm\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    y_pred: numpy.ndarray\n",
    "        array with the predictions\n",
    "    dtrain: lightgbm.Dataset\n",
    "    alpha, gamma: float\n",
    "        See original paper https://arxiv.org/pdf/1708.02002.pdf\n",
    "    num_class: int\n",
    "        number of classes\n",
    "    \"\"\"\n",
    "    a,g = alpha, gamma\n",
    "    y_true = dtrain.label\n",
    "    y_true = np.eye(num_class)[y_true.astype('int')]\n",
    "    y_pred = y_pred.reshape(-1, num_class, order='F')\n",
    "    p = 1/(1+np.exp(-y_pred))\n",
    "    loss = -( a*y_true + (1-a)*(1-y_true) ) * (( 1 - ( y_true*p + (1-y_true)*(1-p)) )**g) * ( y_true*np.log(p)+(1-y_true)*np.log(1-p) )\n",
    "    # a variant can be np.sum(loss)/num_class\n",
    "    return 'focal_loss', np.mean(loss), False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_n_valid_combined = True\n",
    "n_class = pd.concat([df_train_scaled, df_valid_scaled, df_test_scaled])[target].nunique()\n",
    "\n",
    "#config = {\"verbose\": -1}\n",
    "config = {}\n",
    "# config[\"is_unbalance\"] = True\n",
    "# config[\"objective\"] = \"multiclass\"\n",
    "config[\"num_classes\"] = n_class\n",
    "\n",
    "custom = utils.LGBM_custom_score(n_class=n_class)\n",
    "fobj = lambda preds, data: custom.lgbm_focal_loss(preds, data, 0.25, 1.0)\n",
    "#feval = lambda preds, data: focal_loss_lgb_eval_error(preds, data, 0.25, 1.0, n_class)\n",
    "feval = [\n",
    "    lambda preds, data: [\n",
    "        custom.lgbm_focal_loss_eval(preds, data, 0.25, 1.0),\n",
    "         custom.lgbm_f1(preds, data),\n",
    "         custom.lgbm_precision(preds, data),\n",
    "         custom.lgbm_recall(preds, data),\n",
    "         custom.lgbm_accuracy(preds, data),\n",
    "    ]\n",
    "]\n",
    "#ray_metric = \"-\" + \"focal_loss\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbtrain = lgbm.Dataset(\n",
    "    df_train.drop(columns=[target]+[identifier]),\n",
    "    df_train[target],\n",
    "    free_raw_data=False,\n",
    ")\n",
    "lgbvalid = lgbm.Dataset(\n",
    "    df_valid.drop(columns=[target]+[identifier]),\n",
    "    df_valid[target],\n",
    "    reference=lgbtrain,\n",
    "    free_raw_data=False,\n",
    ")\n",
    "\n",
    "if test_n_valid_combined:\n",
    "    df_testNvalid_enc = pd.concat([df_valid, df_test]).reset_index(\n",
    "        drop=True\n",
    "    )\n",
    "    lgbtest = lgbm.Dataset(\n",
    "        df_testNvalid_enc.drop(columns=[target]+[identifier]),\n",
    "        df_testNvalid_enc[target],\n",
    "        free_raw_data=False,\n",
    "    )\n",
    "else:\n",
    "    lgbtest = lgbm.Dataset(\n",
    "        df_test.drop(columns=[target]+[identifier]),\n",
    "        df_test[target],\n",
    "        reference=lgbtrain,\n",
    "        free_raw_data=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006237 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 832051, number of used features: 9\n",
      "[LightGBM] [Warning] Using self-defined objective function\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\tvalid_0's focal_loss: 0.215605\tvalid_0's f1: 0.887934\tvalid_0's precision: 0.888266\tvalid_0's recall_0: 0.890163\tvalid_0's accuracy: 0.888266\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2]\tvalid_0's focal_loss: 0.188667\tvalid_0's f1: 0.889244\tvalid_0's precision: 0.889689\tvalid_0's recall_0: 0.894021\tvalid_0's accuracy: 0.889689\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3]\tvalid_0's focal_loss: 0.165771\tvalid_0's f1: 0.897054\tvalid_0's precision: 0.895756\tvalid_0's recall_0: 0.900642\tvalid_0's accuracy: 0.895756\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4]\tvalid_0's focal_loss: 0.146172\tvalid_0's f1: 0.898813\tvalid_0's precision: 0.897189\tvalid_0's recall_0: 0.902035\tvalid_0's accuracy: 0.897189\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[5]\tvalid_0's focal_loss: 0.129293\tvalid_0's f1: 0.89918\tvalid_0's precision: 0.897891\tvalid_0's recall_0: 0.901601\tvalid_0's accuracy: 0.897891\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    291\u001b[0m                                     evaluation_result_list=None))\n\u001b[1;32m    292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m         \u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   3027\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__set_objective_to_none\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3028\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_parameter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"objective\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"none\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__set_objective_to_none\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3029\u001b[0;31m             \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__inner_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3030\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__boost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_3906/2022256575.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(preds, data)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mcustom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLGBM_custom_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mfobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcustom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlgbm_focal_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;31m#feval = lambda preds, data: focal_loss_lgb_eval_error(preds, data, 0.25, 1.0, n_class)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m feval = [\n",
      "\u001b[0;32m/mnt/c/#work/FIREMAN/FIREMAN-project/src/utils.py\u001b[0m in \u001b[0;36mlgbm_focal_loss\u001b[0;34m(self, preds_raw, lgbDataset, alpha, gamma)\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0mpartial_fl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_focal_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mderivative\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartial_fl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m         \u001b[0mhess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mderivative\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartial_fl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_class\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'F'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'F'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/scipy/misc/common.py\u001b[0m in \u001b[0;36mderivative\u001b[0;34m(func, x0, dx, n, args, order)\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0mho\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0morder\u001b[0m \u001b[0;34m>>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m         \u001b[0mval\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx0\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mho\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mval\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mprod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/c/#work/FIREMAN/FIREMAN-project/src/utils.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    167\u001b[0m             \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreds_raw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'int'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0mpartial_fl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_focal_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m         \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mderivative\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartial_fl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0mhess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mderivative\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartial_fl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/c/#work/FIREMAN/FIREMAN-project/src/utils.py\u001b[0m in \u001b[0;36m_focal_loss\u001b[0;34m(self, y_pred, y_true, alpha, gamma)\u001b[0m\n\u001b[1;32m    135\u001b[0m         loss = (\n\u001b[1;32m    136\u001b[0m             \u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0my_true\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m             \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m             \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = lgbm.train(\n",
    "    config,\n",
    "    lgbtrain,\n",
    "    valid_sets=[lgbvalid],\n",
    "    fobj=fobj,\n",
    "    feval=feval,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.92      0.95    126433\n",
      "           1       0.10      0.50      0.17      1622\n",
      "           2       0.49      0.78      0.60      4952\n",
      "           3       0.12      0.26      0.17      3709\n",
      "           4       0.00      0.00      0.00       202\n",
      "           5       0.36      0.87      0.51      3298\n",
      "           6       0.14      0.33      0.20      3375\n",
      "           7       0.59      0.80      0.68      5892\n",
      "           8       0.22      0.21      0.22      8595\n",
      "           9       0.13      0.20      0.16      5105\n",
      "          10       0.14      0.32      0.20      3567\n",
      "          11       0.68      0.44      0.53     12306\n",
      "          12       0.00      0.00      0.00        49\n",
      "          13       0.79      0.22      0.34     28908\n",
      "\n",
      "    accuracy                           0.70    208013\n",
      "   macro avg       0.34      0.42      0.34    208013\n",
      "weighted avg       0.80      0.70      0.72    208013\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted = model.predict(lgbtest.data).argmax(axis=1)\n",
    "actual = lgbtest.label\n",
    "print(classification_report(predicted, actual))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## w RayTune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2021-11-08 10:38:03 (running for 00:00:01.22)<br>Memory usage on this node: 3.0/12.2 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
       "Bracket: Iter 90.000: None | Iter 30.000: None | Iter 10.000: None<br>Resources requested: 0/8 CPUs, 0/0 GPUs, 0.0/6.47 GiB heap, 0.0/3.24 GiB objects<br>Result logdir: /home/palo/ray_results/training_function_2021-11-08_10-38-02<br>Number of trials: 2/2 (2 ERROR)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status  </th><th>loc              </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_91209_00000</td><td>ERROR   </td><td>172.18.71.208:626</td></tr>\n",
       "<tr><td>training_function_91209_00001</td><td>ERROR   </td><td>172.18.71.208:624</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 2<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                                                </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_91209_00000</td><td style=\"text-align: right;\">           1</td><td>/home/palo/ray_results/training_function_2021-11-08_10-38-02/training_function_91209_00000_0_2021-11-08_10-38-02/error.txt</td></tr>\n",
       "<tr><td>training_function_91209_00001</td><td style=\"text-align: right;\">           1</td><td>/home/palo/ray_results/training_function_2021-11-08_10-38-02/training_function_91209_00001_1_2021-11-08_10-38-02/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TuneError",
     "evalue": "('Trials did not complete', [training_function_91209_00000, training_function_91209_00001])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTuneError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_409/1918576441.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m )\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m analysis = tune.run(\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0mtune\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlgbtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlgbvalid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;31m# resources_per_trial={\"cpu\": 4, \"gpu\": 0},\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/ray/tune/tune.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(run_or_experiment, name, metric, mode, stop, time_budget_s, config, resources_per_trial, num_samples, local_dir, search_alg, scheduler, keep_checkpoints_num, checkpoint_score_attr, checkpoint_freq, checkpoint_at_end, verbose, progress_reporter, log_to_file, trial_name_creator, trial_dirname_creator, sync_config, export_formats, max_failures, fail_fast, restore, server_port, resume, queue_trials, reuse_actors, trial_executor, raise_on_failed_trial, callbacks, max_concurrent_trials, loggers, _remote)\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mincomplete_trials\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    623\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mraise_on_failed_trial\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msignal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSIGINT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 624\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTuneError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Trials did not complete\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincomplete_trials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    625\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Trials did not complete: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincomplete_trials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTuneError\u001b[0m: ('Trials did not complete', [training_function_91209_00000, training_function_91209_00001])"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "\n",
    "#config[\"eta\"] = tune.loguniform(1e-4, 1e-1),\n",
    "#config[\"subsample\"] = tune.uniform(0.5, 1.0),\n",
    "config[\"max_depth\"] = tune.randint(1, 9),\n",
    "# config[\"wandb\"][\"project\"] = \"GBM_classifier\",\n",
    "# config[\"wandb\"][\"api_key_file\"] = \"../data/wandb_api.key\",\n",
    "# config[\"wandb\"][\"log_config\"] = True\n",
    "\n",
    "\n",
    "def training_function(config, train, valid):\n",
    "    lgbm_config = config.copy()\n",
    "    #lgbm_config.pop(\"wandb\")\n",
    "    trainer = lgbm.train(\n",
    "        lgbm_config,\n",
    "        train,\n",
    "        valid_sets=[valid],\n",
    "        valid_names=[\"\"],\n",
    "        callbacks=[\n",
    "            TuneReportCheckpointCallback(\n",
    "                {\n",
    "                    ray_metric: ray_metric,\n",
    "                }\n",
    "            )\n",
    "        ],\n",
    "    )\n",
    "\n",
    "\n",
    "asha_scheduler = AsyncHyperBandScheduler(\n",
    "    time_attr=\"training_iteration\",\n",
    "    metric=ray_metric,\n",
    "    mode=\"min\",\n",
    "    max_t=100,\n",
    "    grace_period=10,\n",
    "    reduction_factor=3,\n",
    "    brackets=1,\n",
    ")\n",
    "\n",
    "analysis = tune.run(\n",
    "    tune.with_parameters(training_function, train=lgbtrain, valid=lgbvalid),\n",
    "    # resources_per_trial={\"cpu\": 4, \"gpu\": 0},\n",
    "    num_samples=2,\n",
    "    progress_reporter=JupyterNotebookReporter(overwrite=True),\n",
    "    scheduler=asha_scheduler,\n",
    "    config=config,\n",
    "    #loggers=DEFAULT_LOGGERS + (WandbLogger,),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.trial_dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train best params model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runtime = time() - start\n",
    "print(\"Optimization time:\\n{}\".format(runtime))\n",
    "\n",
    "params = copy(analysis.get_best_config(ray_metric, \"min\"))\n",
    "params.pop(\"wandb\")\n",
    "# params[\"n_estimators\"] = 1000\n",
    "\n",
    "start = time()\n",
    "model = lgbm.train(\n",
    "    params,\n",
    "    flgbtrain,\n",
    "    valid_sets=[lgbtest],\n",
    "    callbacks=[lgbm.log_evaluation(show_stdv=False)],\n",
    ")\n",
    "runtime = time() - start\n",
    "print(\"Final model training time:\\n{}\".format(str(datetime.timedelta(seconds=runtime))))a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorboard visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboard import notebook\n",
    "\n",
    "notebook.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir ~/ray_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, tab_preprocessor = utils.dl_train_prep(\n",
    "    data_train=df_train_scaled,\n",
    "    data_valid=df_valid_scaled,\n",
    "    identifier=identifier,\n",
    "    cont_cols=cont_cols,\n",
    "    target_col=target,\n",
    ")\n",
    "\n",
    "test_n_valid_combined = True\n",
    "# X_tab_test = tab_preprocessor.transform(data_test_scaled).astype(float)\n",
    "if test_n_valid_combined:\n",
    "    test = pd.concat([df_valid_scaled, df_test_scaled]).reset_index(drop=True)\n",
    "else:\n",
    "    test = df_test_scaled.copy()\n",
    "\n",
    "X_test = {\"X_tab\": tab_preprocessor.transform(test)}\n",
    "\n",
    "n_classes = pd.concat([df_train_scaled, df_valid_scaled, df_test_scaled])[target].nunique()\n",
    "metrics = utils.dl_metrics(n_classes)\n",
    "\n",
    "\n",
    "input_layer = len(tab_preprocessor.continuous_cols)\n",
    "output_layer = n_classes\n",
    "hidden_layers = utils.dl_design(\n",
    "    input_layer, 2, output_layer, design=\"funnel\"\n",
    ").hidden_layers()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TabMLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deeptabular_net = TabMlp(\n",
    "    mlp_hidden_dims=hidden_layers,\n",
    "    column_idx=tab_preprocessor.column_idx,\n",
    "    continuous_cols=tab_preprocessor.continuous_cols,\n",
    "    mlp_batchnorm=True,\n",
    "    mlp_batchnorm_last=True,\n",
    "    mlp_linear_first=True,\n",
    ")\n",
    "model = WideDeep(deeptabular=deeptabular_net, pred_dim=output_layer)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializers/Optimizers/Schedulers/callbacks\n",
    "initializers = {\"deeptabular\": XavierNormal}\n",
    "deeptab_opt = NAdam(model.deeptabular.parameters(), lr=0.001)\n",
    "deeptab_sch = lr_scheduler.StepLR(deeptab_opt, step_size=5)\n",
    "optimizers = {\"deeptabular\": deeptab_opt}\n",
    "schedulers = {\"deeptabular\": deeptab_sch}\n",
    "\n",
    "early_stopping = EarlyStopping()\n",
    "model_checkpoint = ModelCheckpoint(save_best_only=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "objective = \"multiclass_focal_loss\"\n",
    "dataloader = DataLoaderImbalanced\n",
    "\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    objective=objective,\n",
    "    callbacks=[early_stopping, model_checkpoint],\n",
    "    lr_schedulers=schedulers,\n",
    "    initializers=initializers,\n",
    "    optimizers=optimizers,\n",
    "    metrics=metrics,\n",
    ")\n",
    "\n",
    "trainer.fit(\n",
    "    X_train=X_train,\n",
    "    X_val=X_valid,\n",
    "    n_epochs=50,\n",
    "    batch_size=1000,\n",
    "    custom_dataloader=dataloader,\n",
    "    oversample_mul=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual = test[target_ltv]\n",
    "predicted = trainer.predict(**X_test)\n",
    "#predicted_mc = trainer.predict_uncertainty(**X_test, uncertainty_granularity=10)[:, -1],\n",
    "classification_report(predicted, actual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SAINT(\n",
    "    input_dim=input_layer,\n",
    "    column_idx=tab_preprocessor.column_idx,\n",
    "    continuous_cols=tab_preprocessor.continuous_cols,\n",
    ")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializers/Optimizers/Schedulers/callbacks\n",
    "initializers = {\"deeptabular\": XavierNormal}\n",
    "deeptab_opt = NAdam(model.deeptabular.parameters(), lr=0.001)\n",
    "deeptab_sch = lr_scheduler.StepLR(deeptab_opt, step_size=5)\n",
    "optimizers = {\"deeptabular\": deeptab_opt}\n",
    "schedulers = {\"deeptabular\": deeptab_sch}\n",
    "\n",
    "early_stopping = EarlyStopping()\n",
    "model_checkpoint = ModelCheckpoint(save_best_only=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "objective = \"multiclass_focal_loss\"\n",
    "dataloader = DataLoaderImbalanced\n",
    "\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    objective=objective,\n",
    "    callbacks=[early_stopping, model_checkpoint],\n",
    "    lr_schedulers=schedulers,\n",
    "    initializers=initializers,\n",
    "    optimizers=optimizers,\n",
    "    metrics=metrics,\n",
    ")\n",
    "\n",
    "trainer.fit(\n",
    "    X_train=X_train,\n",
    "    X_val=X_valid,\n",
    "    n_epochs=50,\n",
    "    batch_size=1000,\n",
    "    custom_dataloader=dataloader,\n",
    "    oversample_mul=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual = test[target_ltv]\n",
    "predicted = trainer.predict(**X_test)\n",
    "#predicted_mc = trainer.predict_uncertainty(**X_test, uncertainty_granularity=10)[:, -1],\n",
    "classification_report(predicted, actual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BayesianTabMlp(\n",
    "    mlp_hidden_dims=hidden_layers,\n",
    "    column_idx=tab_preprocessor.column_idx,\n",
    "    continuous_cols = tab_preprocessor.continuous_cols,\n",
    ")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializers/Optimizers/Schedulers/callbacks\n",
    "initializers = {\"deeptabular\": XavierNormal}\n",
    "deeptab_opt = NAdam(model.deeptabular.parameters(), lr=0.001)\n",
    "deeptab_sch = lr_scheduler.StepLR(deeptab_opt, step_size=5)\n",
    "optimizers = {\"deeptabular\": deeptab_opt}\n",
    "schedulers = {\"deeptabular\": deeptab_sch}\n",
    "\n",
    "early_stopping = EarlyStopping()\n",
    "model_checkpoint = ModelCheckpoint(save_best_only=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "objective = \"multiclass_focal_loss\"\n",
    "dataloader = DataLoaderImbalanced\n",
    "\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    objective=objective,\n",
    "    callbacks=[early_stopping, model_checkpoint],\n",
    "    lr_schedulers=schedulers,\n",
    "    initializers=initializers,\n",
    "    optimizers=optimizers,\n",
    "    metrics=metrics,\n",
    ")\n",
    "\n",
    "trainer.fit(\n",
    "    X_train=X_train,\n",
    "    X_val=X_valid,\n",
    "    n_epochs=50,\n",
    "    batch_size=1000,\n",
    "    custom_dataloader=dataloader,\n",
    "    oversample_mul=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual = test[target_ltv]\n",
    "predicted = trainer.predict(**X_test)\n",
    "#predicted_mc = trainer.predict_uncertainty(**X_test, uncertainty_granularity=10)[:, -1],\n",
    "classification_report(predicted, actual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## w RayTune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Optimizers\n",
    "deep_opt_sgd_01 = SGD(model.deeptabular.parameters(), lr=0.1)\n",
    "deep_opt_sgd_001 = SGD(model.deeptabular.parameters(), lr=0.01)\n",
    "deep_opt_adam_01 = Adam(model.deeptabular.parameters(), lr=0.1)\n",
    "deep_opt_adam_001 = Adam(model.deeptabular.parameters(), lr=0.01)\n",
    "# LR Schedulers\n",
    "deep_sch_StepLR5 = lr_scheduler.StepLR(deep_opt, step_size=5)\n",
    "deep_sch_StepLR10 = lr_scheduler.StepLR(deep_opt, step_size=10)\n",
    "\n",
    "input_layer = len(tab_preprocessor.continuous_cols)\n",
    "output_layer = n_classes\n",
    "\n",
    "hidden_layers2 = utils.dl_design(input_layer, 2, output_layer, design=\"funnel\")\n",
    "hidden_layers3 = utils.dl_design(input_layer, 3, output_layer, design=\"funnel\")\n",
    "hidden_layers5 = utils.dl_design(input_layer, 5, output_layer, design=\"funnel\")\n",
    "hidden_layers10 = utils.dl_design(input_layer, 10, output_layer, design=\"funnel\")\n",
    "\n",
    "config = {\n",
    "    \"batch_size\": tune.grid_search([100, 1000, 10000]),\n",
    "    \"deeptab_opt\": tune.grid_search(\n",
    "        [\n",
    "            deep_opt_sgd_01,\n",
    "            deep_opt_adam_01,\n",
    "            deep_opt_sgd_001,\n",
    "            deep_opt_adam_001,\n",
    "        ]\n",
    "    ),\n",
    "    \"deeptab_sch\": tune.grid_search([deep_sch_StepLR5]),  # , deep_sch_StepLR10]),\n",
    "    \"hidden_layers\": tune.grid_search(\n",
    "        [hidden_layers2, hidden_layers3, hidden_layers5, hidden_layers10]\n",
    "    ),\n",
    "    \"wandb\": {\n",
    "        \"project\": \"dl_gm\",\n",
    "        \"api_key_file\": \"/home/jovyan/repos/pltv/data/wandb_api.key\",\n",
    "    },\n",
    "}\n",
    "\n",
    "objective = \"multiclass_focal_loss\"\n",
    "dataloader = DataLoaderImbalanced\n",
    "\n",
    "\n",
    "@wandb_mixin\n",
    "def training_function(config, X_train, X_val):\n",
    "    early_stopping = EarlyStopping()\n",
    "    model_checkpoint = ModelCheckpoint(save_best_only=True, wb=wandb)\n",
    "\n",
    "    deeptabular = TabMlp(\n",
    "        mlp_hidden_dims=config[\"hidden_layers\"].hidden_layers(),\n",
    "        column_idx=tab_preprocessor.column_idx,\n",
    "        embed_input=tab_preprocessor.embeddings_input,\n",
    "        continuous_cols=tab_preprocessor.continuous_cols,\n",
    "        mlp_batchnorm=True,\n",
    "        mlp_batchnorm_last=True,\n",
    "        mlp_linear_first=True,\n",
    "    )\n",
    "\n",
    "    model = WideDeep(wide=wide, deeptabular=deeptabular)\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model,\n",
    "        objective=objective,\n",
    "        callbacks=[RayTuneReporter, early_stopping, model_checkpoint],\n",
    "        lr_schedulers={\"deeptabular\": config[\"deeptab_sch\"]},\n",
    "        initializers={\"deeptabular\": XavierNormal},\n",
    "        optimizers={\"deeptabular\": config[\"deeptab_opt\"]},\n",
    "        metrics=metrics,\n",
    "        verbose=0,\n",
    "    )\n",
    "\n",
    "    trainer.fit(\n",
    "        X_train=X_train,\n",
    "        X_val=X_val,\n",
    "        n_epochs=50,\n",
    "        batch_size=config[\"batch_size\"],\n",
    "        custom_dataloader=dataloader,\n",
    "        oversample_mul=5,\n",
    "    )\n",
    "\n",
    "\n",
    "# https://docs.ray.io/en/latest/tune/api_docs/schedulers.html#tune-scheduler-hyperband\n",
    "asha_scheduler = AsyncHyperBandScheduler(\n",
    "    time_attr=\"training_iteration\",\n",
    "    metric=\"_metric/val_loss\",\n",
    "    mode=\"min\",\n",
    "    max_t=100,\n",
    "    grace_period=10,\n",
    "    reduction_factor=3,\n",
    "    brackets=1,\n",
    ")\n",
    "\n",
    "analysis = tune.run(\n",
    "    tune.with_parameters(training_function, X_train=X_train, X_val=X_valid),\n",
    "    # resources_per_trial={\"cpu\": 4, \"gpu\": 0},\n",
    "    num_samples=1,\n",
    "    progress_reporter=JupyterNotebookReporter(overwrite=True),\n",
    "    scheduler=asha_scheduler,\n",
    "    config=config,\n",
    "    callbacks=[\n",
    "        WandbLoggerCallback(\n",
    "            project=config[\"wandb\"][\"project\"],\n",
    "            api_key_file=config[\"wandb\"][\"api_key_file\"],\n",
    "            log_config=True,\n",
    "        )\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "params = copy(analysis.get_best_config(\"_metric/val_loss\", \"min\"))\n",
    "params.pop(\"wandb\")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    objective=objective,\n",
    "    callbacks=[LRHistory(n_epochs=10)],\n",
    "    lr_schedulers={\"wide\": params[\"wide_sch\"], \"deeptabular\": params[\"deeptab_sch\"]},\n",
    "    initializers={\"wide\": XavierNormal, \"deeptabular\": XavierNormal},\n",
    "    optimizers={\"wide\": params[\"wide_opt\"], \"deeptabular\": params[\"deeptab_opt\"]},\n",
    "    metrics=metrics,\n",
    "    verbose=0,\n",
    ")\n",
    "\n",
    "trainer.fit(\n",
    "    X_train=X_train,\n",
    "    X_val=X_val,\n",
    "    n_epochs=5,\n",
    "    batch_size=params[\"batch_size\"],\n",
    "    custom_dataloader=dataloader,\n",
    "    oversample_mul=5,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
