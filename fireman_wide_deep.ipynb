{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports\n",
    "**Other**\n",
    "* CPU monitoring in terminal:  \n",
    "```bash\n",
    "top\n",
    "```\n",
    "* GPU monitoring in terminal:  \n",
    "```bash\n",
    "pip install gpustat\n",
    "watch -c gpustat -cp --color\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "# to save results to data directory\n",
    "module_path = '..'\n",
    "if module_path not in sys.path:\n",
    "    sys.path.insert(1, module_path)\n",
    "# increase displayed columns in jupyter notebook\n",
    "pd.set_option('display.max_columns', 200)\n",
    "pd.set_option('display.max_rows', 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import multiprocessing\n",
    "import json\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import MinMaxScaler, PowerTransformer, RobustScaler, StandardScaler\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pytorch_widedeep.dataloaders import DataLoaderImbalanced, DataLoaderDefault\n",
    "from pytorch_widedeep.preprocessing import WidePreprocessor, TabPreprocessor\n",
    "from pytorch_widedeep.training import Trainer\n",
    "from pytorch_widedeep.models import Wide, TabMlp, WideDeep\n",
    "from pytorch_widedeep.models.transformers.saint import SAINT\n",
    "from pytorch_widedeep.callbacks import EarlyStopping, ModelCheckpoint, LRHistory\n",
    "from pytorch_widedeep.initializers import KaimingNormal, XavierNormal\n",
    "from pytorch_widedeep.callbacks import ModelCheckpoint, LRHistory, EarlyStopping\n",
    "from pytorch_widedeep.optim import RAdam\n",
    "\n",
    "from torch.optim import SGD, lr_scheduler\n",
    "from torchmetrics import F1 as F1_torchmetrics\n",
    "from torchmetrics import Accuracy as Accuracy_torchmetrics\n",
    "from torchmetrics import Precision as Precision_torchmetrics\n",
    "from torchmetrics import Recall as Recall_torchmetrics\n",
    "\n",
    "# increase displayed columns in jupyter notebook\n",
    "pd.set_option('display.max_columns', 200)\n",
    "pd.set_option('display.max_rows', 300)\n",
    "\n",
    "# temporarily remove deprecation warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**helper functions for scaling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intsec(list1, list2):\n",
    "    \"\"\"Simple intesection of two lists.\n",
    "\n",
    "    Args:\n",
    "        list1 (list): list1\n",
    "        list2 (list): list2\n",
    "\n",
    "    Returns:\n",
    "        list (list): intersection of lists\n",
    "    \"\"\"\n",
    "    return list(set.intersection(set(list1), set(list2)))\n",
    "\n",
    "\n",
    "def scale(data_pd, non_scale_cols, scaler_sk='Standard'):\n",
    "    \"\"\"Procedure to scale the dataset except the given list of columns.\n",
    "\n",
    "    Args:\n",
    "        data_pd (obj): pandas dataframe\n",
    "        non_scale_cols (list): columns to not scale\n",
    "        scaler_sk (str, sklearn.peprocessing obj): type of scaler from['Standard', 'Yeo-Johnson',\n",
    "        'Robust', 'MinMax'] or already fitted scaler\n",
    "\n",
    "    Returns:\n",
    "        tuple (tuple): data_pd_scaled (obj): scaled pandas dataframe\\n\n",
    "        scaler_sk (obj): sklearn scaler object\n",
    "    \"\"\"\n",
    "    non_scale_cols = intsec(data_pd.columns.values, non_scale_cols)\n",
    "    data_pd_toscale = data_pd.drop(columns=non_scale_cols)\n",
    "    if type(scaler_sk) is str:\n",
    "        if scaler_sk == 'Standard':\n",
    "            scaler_sk = StandardScaler()\n",
    "        elif scaler_sk == 'Yeo-Johnson':\n",
    "            scaler_sk = PowerTransformer(method='yeo-johnson')\n",
    "        elif scaler_sk == 'Robust':\n",
    "            scaler_sk = RobustScaler()\n",
    "        elif scaler_sk == 'MinMax':\n",
    "            scaler_sk = MinMaxScaler()\n",
    "        scaler_sk.fit(data_pd_toscale)\n",
    "    # if 'sklearn.peprocessing' in str(type(scaler_sk)):\n",
    "\n",
    "    data_pd_scaled = pd.DataFrame(scaler_sk.transform(data_pd_toscale),\n",
    "                                  columns=data_pd_toscale.columns.values)\n",
    "    data_pd_scaled[non_scale_cols] = data_pd[non_scale_cols].copy()\n",
    "    return data_pd_scaled, scaler_sk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# PyTorch interop threads: 4\n",
      "# PyTorch threads: 4\n",
      "# of available CPUs: 8\n"
     ]
    }
   ],
   "source": [
    "# https://discuss.pytorch.org/t/why-is-pytorch-using-only-the-half-of-cpu-cores-smt-enabled/69068\n",
    "# https://pytorch.org/docs/stable/torch.html#parallelism\n",
    "print('# PyTorch interop threads: {}\\n'.format(str(torch.get_num_interop_threads())) +\n",
    "      '# PyTorch threads: {}\\n'.format(str(torch.get_num_threads())) +\n",
    "      '# of available CPUs: {}'.format(str(multiprocessing.cpu_count())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_num_threads(8)\n",
    "torch.set_num_interop_threads(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set (i)identifier and which columns are (ii)numerical and (iii)categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-2e477327e622>:1: ResourceWarning: unclosed file <_io.TextIOWrapper name='../data/column_types_im.json' mode='r' encoding='UTF-8'>\n",
      "  column_types = json.load(open('../data/column_types_im.json', 'r'))\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    }
   ],
   "source": [
    "column_types = json.load(open('./#datasets/column_types.json', 'r'))\n",
    "\n",
    "identifier = column_types['identifier']\n",
    "cat_cols = column_types['categorical']\n",
    "target = column_types['target']\n",
    "random_state = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw = pd.read_pickle('./#datasets/data.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fill NA - 0 for numerical and 'NA' for categorical**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical\n",
    "data_raw[cat_cols] = data_raw[cat_cols].fillna('NA')\n",
    "data_raw[cat_cols] = data_raw[cat_cols].astype(str)\n",
    "# non-categorical\n",
    "non_cat_cols = data_raw.drop(columns=cat_cols + [identifier]).columns.tolist()\n",
    "data_raw[non_cat_cols] = data_raw[non_cat_cols].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Constant columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "const_cols = data_raw.columns[data_raw.nunique() == 1].values.tolist()\n",
    "data_raw.drop(columns=const_cols, inplace=True)\n",
    "print('Dropped constant columns:\\n{}'.format(const_cols))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train, valid, test dataset split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_valid = train_test_split(data_raw, test_size=0.2, stratify=data_raw[target], random_state=1)\n",
    "data_valid, data_test = train_test_split(data_valid, test_size=0.5, stratify=data_valid[target], random_state=1)\n",
    "\n",
    "data_train.reset_index(inplace=True, drop=True)\n",
    "data_valid.reset_index(inplace=True, drop=True)\n",
    "data_test.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Widedeep network experiment\n",
    "\n",
    "* based on \n",
    "  * [09_Custom_DataLoader_Imbalanced_dataset.ipynb](https://github.com/jrzaurin/pytorch-widedeep/blob/master/examples/09_Custom_DataLoader_Imbalanced_dataset.ipynb)\n",
    "  * [03_Binary_Classification_with_Defaults](https://github.com/jrzaurin/pytorch-widedeep/blob/master/examples/03_Binary_Classification_with_Defaults.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_scaled, Scaler_cls = scale(\n",
    "    data_train, cat_cols+[target], scaler_sk='Standard')\n",
    "\n",
    "data_valid_scaled, Scaler_cls = scale(\n",
    "    data_valid, cat_cols+[target], scaler_sk=Scaler_cls)\n",
    "\n",
    "data_test_scaled, Scaler_cls = scale(\n",
    "    data_test, cat_cols+[target], scaler_sk=Scaler_cls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[CHECK] Dataset imbalance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_scaled[target].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CUDA vs CPU use in widedeep should be automaticall**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://pytorch-widedeep.readthedocs.io/en/latest/_modules/pytorch_widedeep/training/trainer.html?highlight=cuda\n",
    "os.cpu_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Per class metrics](https://pytorch-widedeep.readthedocs.io/en/latest/metrics.html)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics from torchmetrics\n",
    "accuracy = Accuracy_torchmetrics(average=None, num_classes=2)\n",
    "precision = Precision_torchmetrics(average='micro', num_classes=2)\n",
    "f1 = F1_torchmetrics(average=None, num_classes=2)\n",
    "recall = Recall_torchmetrics(average=None, num_classes=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "wide_cols = intsec(cat_cols, data_train.columns.values.tolist())\n",
    "continuous_cols = data_raw.drop(columns=[target]+wide_cols).columns.values.tolist()\n",
    "#crossed_cols = [('X', 'Y'), ('W', 'Q')]\n",
    "\n",
    "embed_cols = wide_cols\n",
    "embed_input = [(u,i) for u,i in zip(embed_cols, [4]*len(embed_cols))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/pytorch_widedeep-1.0.9-py3.8.egg/pytorch_widedeep/preprocessing/tab_preprocessor.py:179: UserWarning: Continuous columns will not be normalised\n",
      "  warnings.warn(\"Continuous columns will not be normalised\")\n"
     ]
    }
   ],
   "source": [
    "# wide\n",
    "wide_preprocessor = WidePreprocessor(wide_cols=wide_cols)\n",
    "X_wide_train = wide_preprocessor.fit_transform(data_train_scaled)\n",
    "X_wide_valid = wide_preprocessor.transform(data_valid_scaled)\n",
    "X_wide_test = wide_preprocessor.transform(data_test_scaled)\n",
    "\n",
    "# deeptabular\n",
    "tab_preprocessor = TabPreprocessor(#embed_cols=embed_input,\n",
    "                                   continuous_cols=continuous_cols,\n",
    "                                   scale=False)\n",
    "X_tab_train = tab_preprocessor.fit_transform(data_train_scaled)\n",
    "X_tab_valid = tab_preprocessor.transform(data_valid_scaled)\n",
    "X_tab_test = tab_preprocessor.transform(data_test_scaled)\n",
    "\n",
    "# target\n",
    "y_train = data_train_scaled[target].values\n",
    "y_valid = data_valid_scaled[target].values\n",
    "y_test = data_test_scaled[target].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the model\n",
    "* batchnorm at each layers in combination with scaling of input layers helps with [efficiency of backprop](https://stats.stackexchange.com/a/328988)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[OPTIONAL] test different hidden layer designs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = len(tab_preprocessor.continuous_cols)\n",
    "output_layer = 1\n",
    "\n",
    "lengths = [3,5,7,9,11]\n",
    "\n",
    "pipes = []\n",
    "anti_autoencoders = []\n",
    "trapezoids = []\n",
    "anti_trapezoids = []\n",
    "funnels = []\n",
    "adj_funnels = []\n",
    "apollos = []\n",
    "\n",
    "for length in lengths:\n",
    "    pipe = [input_layer]*length\n",
    "    pipes.append(pipe)\n",
    "    anti_autoencoder = np.linspace(input_layer, input_layer*2, ceil(length/2), dtype=int).tolist()\n",
    "    anti_autoencoder.extend(anti_autoencoder[-2::-1])\n",
    "    anti_autoencoders.append(anti_autoencoder)\n",
    "    trapezoid = np.array([round(input_layer*1.25)]*length)\n",
    "    trapezoid[[0, -1]] = input_layer\n",
    "    trapezoids.append(trapezoid.tolist())\n",
    "    anti_trapezoid = np.array([round(input_layer*0.75)]*length)\n",
    "    anti_trapezoid[[0, -1]] = input_layer\n",
    "    anti_trapezoids.append(anti_trapezoid.tolist())\n",
    "    funnel = np.linspace(input_layer*2, output_layer, length, endpoint=False, dtype=int).tolist()\n",
    "    funnels.append(funnel)\n",
    "    adj_funnel = np.linspace(input_layer*2, output_layer, length, endpoint=False, dtype=int).tolist()\n",
    "    adj_funnel.insert(0, input_layer)\n",
    "    adj_funnels.append(adj_funnel)\n",
    "    apollo = np.linspace(input_layer, input_layer*2, length, dtype=int).tolist()\n",
    "    apollos.append(apollo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = len(tab_preprocessor.continuous_cols)\n",
    "output_layer = 1\n",
    "hidden_layers = np.linspace(input_layer*2, output_layer, 5, endpoint=False, dtype=int).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wide = Wide(wide_dim=wide_preprocessor.wide_dim)\n",
    "'''\n",
    "deeptabular = SAINT(mlp_hidden_dims=hidden_layers,\n",
    "                     column_idx=tab_preprocessor.column_idx,\n",
    "                     #embed_input=tab_preprocessor.embeddings_input,\n",
    "                     continuous_cols=tab_preprocessor.continuous_cols,\n",
    "                     mlp_batchnorm=True,\n",
    "                     mlp_batchnorm_last=True,\n",
    "                     mlp_linear_first=True)\n",
    "'''\n",
    "deeptabular = TabMlp(mlp_hidden_dims=hidden_layers,\n",
    "                     column_idx=tab_preprocessor.column_idx,\n",
    "                     #embed_input=tab_preprocessor.embeddings_input,\n",
    "                     continuous_cols=tab_preprocessor.continuous_cols,\n",
    "                     mlp_batchnorm=True,\n",
    "                     mlp_batchnorm_last=True,\n",
    "                     mlp_linear_first=True)\n",
    "model = WideDeep(wide=wide, deeptabular=deeptabular)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Optimizers, LR schedulers, Initializers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizers\n",
    "wide_opt = SGD(model.wide.parameters(), lr=0.01)\n",
    "deep_opt = SGD(model.deeptabular.parameters(), lr=0.01)\n",
    "# LR Schedulers\n",
    "wide_sch = lr_scheduler.StepLR(wide_opt, step_size=3)\n",
    "deep_sch = lr_scheduler.StepLR(deep_opt, step_size=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping()\n",
    "model_checkpoint = ModelCheckpoint(filepath=\"/#datasets/temp/wide\",\n",
    "                                   save_best_only=True,\n",
    "                                   verbose=1,\n",
    "                                   max_save=1)\n",
    "\n",
    "trainer = Trainer(model,\n",
    "                  objective=\"binary_focal_loss\",\n",
    "                  callbacks=[LRHistory(n_epochs=10), early_stopping, model_checkpoint],\n",
    "                  lr_schedulers={'wide': wide_sch, 'deeptabular':deep_sch},\n",
    "                  initializers={'wide': XavierNormal, 'deeptabular':XavierNormal},\n",
    "                  optimizers = {'wide': wide_opt, 'deeptabular':deep_opt},\n",
    "                  metrics=[accuracy, precision, recall, f1])\n",
    "\n",
    "trainer.fit(X_train={\"X_wide\": X_wide_train, \"X_tab\": X_tab_train, \"target\": y_train},\n",
    "            X_val={\"X_wide\": X_wide_valid, \"X_tab\": X_tab_valid, \"target\": y_valid},\n",
    "            n_epochs=10,\n",
    "            batch_size=1000,\n",
    "            custom_dataloader=DataLoaderImbalanced,\n",
    "            oversample_mul=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(trainer.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(trainer.lr_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Predict**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "predict: 100%|██████████| 190/190 [00:03<00:00, 53.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.86      0.92    187489\n",
      "           1       0.04      0.49      0.08      2388\n",
      "\n",
      "    accuracy                           0.86    189877\n",
      "   macro avg       0.52      0.68      0.50    189877\n",
      "weighted avg       0.98      0.86      0.91    189877\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_pred = trainer.predict(X_wide=X_wide_test, X_tab=X_tab_test)\n",
    "print(classification_report(data_test[target].to_list(), data_cls01_pred))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d9d18e9f29cc76176cc64cecda10b08503df27bbeb68d46276fb666f16272d10"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}